{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be1232da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e3f7d",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d2ad19",
   "metadata": {},
   "source": [
    "В логистической регрессии мы предсказываем вероятность появления одного из событий. Предположим, у нас бинарное событие. Например, если бы книги оценивались просто как \"хорошие\", \"плохие\", то мы бы пытались предсказать вероятность, с какой книгам ставят оценку \"хорошая\", \"плохая\". Но искать вероятность можно не только для бинарных событий. Это могут быть и непрерывные величины. В наших реальных данных оценка книги ставится не как \"хорошая\", \"плохая\", а как 3 или 4, а предсказываем мы среднее значение, которое может быть 3,9.\n",
    "\n",
    "Сразу оговорим условия применения модели:\n",
    "\n",
    "1) категориальные переменные должны быть закодированы;\n",
    "2) непрерывные переменные должны быть масштабированы и приведены к нормальному распределению;\n",
    "3) независимость переменных;\n",
    "4) наличие линейной зависимости между хотя бы одной перtменной и логитом зависимой переменной;\n",
    "5) отсутствие мультиколлинеарности между переменными;\n",
    "6) отсутствие дисбаланса классов.\n",
    "\n",
    "Теперь посмотрим, как же решается задача логистической регрессии.\n",
    "\n",
    "Вспомним, что в линейной регрессии исходят из того, что зависимую переменную может дать формула:\n",
    "\n",
    "$$ f(X) = \\beta_0 + \\beta_1 X_1$$\n",
    "\n",
    "В логистической регрессии ищут не само Y, а вероятность Y, что можно записать так:\n",
    "\n",
    "$$ E(Y|x) = \\beta_0 + \\beta_1 x $$\n",
    "\n",
    "Мы видим, что слева стоит E(Y|x), которое, раз это вероятность, может принять значение только между 0 и 1. Справа же стоит выражение, которое может оказаться любым, а значит за границами отрезка от 0 до 1. Значит, если мы хотим найти, какие коэффициент справа дают наибольшую вероятность получить искомый Y, надо надо что-то изменить. Менять формулу справа смысла нет, ведь она \"работает\" с переменными, подгоняет их. Нам надо изменить формулу слева, то есть заставить вероятность \"работать\" не в границах между 0 и 1, а в границах от минус бесконечности до плюс бесконечности. Вот как этого добиваются. Для начала превратим вероятность в шансы (odds). Для этого нужно поделить вероятность желаемого события (P) на вероятность обратного желаемому событию (1–P). \n",
    "\n",
    "$$Odds = \\frac{P}{1-P} \\in [0, +\\infty)$$\n",
    "\n",
    "Однако это даст результаты только в границах от нуля до плюс бесконечности, а нам нужно от минус бесконечности до плюс бесконечности. Этого можно добиться, если перевести нашу формулу в логарифмическую форму.\n",
    "\n",
    "$$\\ln(Odds) = \\ln\\left(\\frac{P}{1-P}\\right) \\in (-\\infty, +\\infty)$$\n",
    "\n",
    "Тогда у нас вероятность определяется на минус бесконечности – плюс бесконечности, как и формула линейной регрессии:\n",
    "\n",
    "$$\\ln\\left(\\frac{P}{1-P}\\right) = \\beta_0 + \\beta_1 x$$\n",
    "\n",
    "Особенность этого уравнения в том, что его права часть дает линейную зависимость, а вот левая - нелинейную. Но теперь мы все-таки хотим получить вероятность, то есть P. Для этого нужно избавиться от логарифма слева. У нас слева натуральный логарифм, значит можно записать в равнозначной форме:\n",
    "\n",
    "$$e^{\\ln\\left(\\frac{P}{1-P}\\right)} = e^{\\beta_0 + \\beta_1 x}$$\n",
    "\n",
    "Слева экспонента и логарифм \"погашают\" друг друга:\n",
    "\n",
    "$$\\frac{P}{1-P} = e^{\\beta_0 + \\beta_1 x}$$\n",
    "\n",
    "Дальше выполняем такие преобразования:\n",
    "\n",
    "$$P = e^{\\beta_0 + \\beta_1 x} (1 - P)$$\n",
    "\n",
    "$$P = e^{\\beta_0 + \\beta_1 x} - P \\cdot e^{\\beta_0 + \\beta_1 x}$$\n",
    "\n",
    "Делаем перенос, выносим общий множитель:\n",
    "\n",
    "$$P (1 + e^{\\beta_0 + \\beta_1 x}) = e^{\\beta_0 + \\beta_1 x}$$\n",
    "\n",
    "Как результат:\n",
    "\n",
    "$$P(Y=1|x) = \\frac{e^{\\beta_0 + \\beta_1 x}}{1 + e^{\\beta_0 + \\beta_1 x}} = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x)}}$$\n",
    "\n",
    "Это называется логит-трансформацией. Логит позволяет сохранить важные свойства линейной регрессии: является линейным по параметрам, может принимать значения x от минус до плюс бесконечности. Теперь мы знаем, как перевести признаки в вероятность события. Нам нужно настроить коэффициенты справа таким образом, чтобы вероятность получить зависимую переменную была максимальной. Это делается с помощью метода наибольшего правдоподобия. \n",
    "\n",
    "Для начала нам надо перейти с $P(Y=1|x)$ к $P(y_i|x_i)$. Разница в том, что $P(Y=1|x)$ показывает вероятность получить значение 1, то есть желаемое нами. А вот $P(y_i|x_i)$ показывает вероятность получить либо 1, либо 0, то есть желаемое или нежелаемое событие. Так как в нашей реальной таблице может быть как 1, так и 0, нам это нужно как-то записать. Делают это так:\n",
    "\n",
    "$$P(y_i|x_i) = p_i^{y_i} \\cdot (1 - p_i)^{1 - y_i}$$\n",
    "\n",
    "Если $y_i = 1$, формула превращается в $p_i^1 \\cdot (1-p_i)^0 = p_i$.\n",
    "\n",
    "Если $y_i = 0$, формула превращается в $p_i^0 \\cdot (1-p_i)^1 = 1 - p_i$.\n",
    "\n",
    "Эту формулу мы должны применить к каждой строке нашей таблицы:\n",
    "\n",
    "$$L(\\beta) = \\prod_{i=1}^{N} p_i^{y_i} (1 - p_i)^{1 - y_i}$$\n",
    "\n",
    "Где $p_i = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_i)}}$.\n",
    "\n",
    "Максимизировать легче логарифм, поэтому формулу надо переписать в логарифмической форме, вот как это сделать.\n",
    "\n",
    "Сначала запишем так:\n",
    "\n",
    "$$L(\\beta) = \\prod_{i=1}^{N} \\underbrace{p_i^{y_i} (1 - p_i)^{1 - y_i}}_{P(y_i|x_i)}$$\n",
    "\n",
    "Берем натуральный логарифм слева и справа:\n",
    "\n",
    "$$LL(\\beta) = \\ln(L(\\beta)) = \\ln\\left( \\prod_{i=1}^{N} p_i^{y_i} (1 - p_i)^{1 - y_i} \\right)$$\n",
    "\n",
    "Используем свойство: $\\ln(a \\cdot b \\cdot c) = \\ln(a) + \\ln(b) + \\ln(c)$.\n",
    "Оператор произведения $\\prod$ превращается в оператор суммирования $\\sum$.\n",
    "\n",
    "$$LL(\\beta) = \\sum_{i=1}^{N} \\ln\\left( p_i^{y_i} \\cdot (1 - p_i)^{1 - y_i} \\right)$$\n",
    "\n",
    "Внутри скобки $\\ln(\\dots)$ у нас все еще произведение двух множителей: $A = p_i^{y_i}$ и $B = (1 - p_i)^{1 - y_i}$.\n",
    "Снова применяем правило $\\ln(A \\cdot B) = \\ln(A) + \\ln(B)$:\n",
    "\n",
    "$$LL(\\beta) = \\sum_{i=1}^{N} \\left[ \\ln(p_i^{y_i}) + \\ln((1 - p_i)^{1 - y_i}) \\right]$$\n",
    "\n",
    "Используем свойство: $\\ln(a^b) = b \\cdot \\ln(a)$.\n",
    "Показатели степени ($y_i$ и $1-y_i$) «спускаются» вниз и становятся множителями перед логарифмом.\n",
    "\n",
    "$$LL(\\beta) = \\sum_{i=1}^{N} [y_i \\cdot \\ln(p_i) + (1 - y_i) \\cdot \\ln(1 - p_i)]$$\n",
    "\n",
    "Именно это уравнение и надо максимизировать. Для этого нам нужно взять производную функции. Наша функция $LL(\\beta)$ зависит от вероятности p, но вероятность p зависит от беты. Значит, учитывая, что производная от суммы функций равна сумме их производных, производную будем искать так:\n",
    "\n",
    "$$\\frac{\\partial LL}{\\partial \\beta} = \\sum_{i=1}^{N} \\left( \\frac{\\partial LL}{\\partial p_i} \\cdot \\frac{\\partial p_i}{\\partial \\beta} \\right)$$\n",
    "\n",
    "Вернемся сюда:\n",
    "\n",
    "$$P(Y=1|x) = \\frac{e^{\\beta_0 + \\beta_1 x}}{1 + e^{\\beta_0 + \\beta_1 x}} = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x)}}$$\n",
    "\n",
    "Запишем это через $$z_i = \\beta_0 + \\beta_1 x_i$$ так:\n",
    "\n",
    "$$p_i = \\sigma(z_i) = \\frac{1}{1 + e^{-z_i}}$$\n",
    "\n",
    "Мы получаем, что $p(z(\\beta))$ сложная функция. Вернемся к $$\\frac{\\partial p_i}{\\partial \\beta}$$, которое как сложная функция даст $$\\frac{\\partial p_i}{\\partial \\beta} = \\frac{\\partial p_i}{\\partial z_i} \\cdot \\frac{\\partial z_i}{\\partial \\beta}$$\n",
    "\n",
    "Итак, у нас было: \n",
    "\n",
    "$$\\frac{\\partial LL}{\\partial \\beta} = \\sum \\left( \\frac{\\partial LL}{\\partial p_i} \\cdot \\mathbf{\\frac{\\partial p_i}{\\partial \\beta}} \\right)$$\n",
    "\n",
    "А теперь, после подстановки, стало так:\n",
    "\n",
    "$$\\frac{\\partial LL}{\\partial \\beta} = \\sum \\left( \\frac{\\partial LL}{\\partial p_i} \\cdot \\underbrace{\\left[ \\frac{\\partial p_i}{\\partial z_i} \\cdot \\frac{\\partial z_i}{\\partial \\beta} \\right]}_{\\text{раскрыли } \\frac{\\partial p_i}{\\partial \\beta}} \\right)$$\n",
    "\n",
    "Или для одного наблюдения:\n",
    "\n",
    "$$\\frac{\\partial LL_i}{\\partial \\beta} = \\underbrace{\\frac{\\partial LL_i}{\\partial p_i}}_{\\text{Шаг 1}} \\cdot \\underbrace{\\frac{\\partial p_i}{\\partial z_i}}_{\\text{Шаг 2}} \\cdot \\underbrace{\\frac{\\partial z_i}{\\partial \\beta}}_{\\text{Шаг 3}}$$\n",
    "\n",
    "Теперь будем выполнять операции по шагам. Начинаем с шага 1. Для одного наблюдения формула вероятности была такой:\n",
    "\n",
    "$$LL_i = y_i \\ln(p_i) + (1 - y_i) \\ln(1 - p_i)$$\n",
    "\n",
    "Дифференцируем по $p_i$. Здесь $y_i$ — константа.\n",
    "\n",
    "1. Первое слагаемое: Производная $\\ln(p_i)$ есть $\\frac{1}{p_i}$.\n",
    "\n",
    "$$\\frac{\\partial}{\\partial p_i} [y_i \\ln(p_i)] = \\frac{y_i}{p_i}$$\n",
    "\n",
    "2. Второе слагаемое: Производная сложной функции $\\ln(1 - p_i)$.\n",
    "Производная внешняя ($\\ln(\\cdot)$) умножить на производную внутреннюю ($1-p_i$).\n",
    "\n",
    "$$\\frac{\\partial}{\\partial p_i} [(1 - y_i) \\ln(1 - p_i)] = (1 - y_i) \\cdot \\frac{1}{1 - p_i} \\cdot \\underbrace{(-1)}_{\\text{производная от } -p_i}$$ $$= - \\frac{1 - y_i}{1 - p_i}$$\n",
    "\n",
    "3. Суммируем и приводим к общему знаменателю:\n",
    "\n",
    "    $$\\frac{\\partial LL_i}{\\partial p_i} = \\frac{y_i}{p_i} - \\frac{1 - y_i}{1 - p_i}$$\n",
    "\n",
    "    Общий знаменатель: $p_i(1 - p_i)$.\n",
    "\n",
    "    $$= \\frac{y_i(1 - p_i) - p_i(1 - y_i)}{p_i(1 - p_i)}$$\n",
    "\n",
    "    Раскрываем скобки в числителе:\n",
    "\n",
    "    $$= \\frac{y_i - y_i p_i - p_i + y_i p_i}{p_i(1 - p_i)}$$\n",
    "\n",
    "    Слагаемые $-y_i p_i$ и $+y_i p_i$ сокращаются.\n",
    "    Результат Шага 1:\n",
    "\n",
    "    $$\\frac{y_i - p_i}{p_i(1 - p_i)}$$\n",
    "\n",
    "Шаг 2. Производная сигмоиды по линейному аргументу ($\\frac{\\partial p_i}{\\partial z_i}$)\n",
    "\n",
    "Это ключевой момент. Нам нужно продифференцировать функцию:\n",
    "\n",
    "\n",
    "$$p_i = \\frac{1}{1 + e^{-z_i}} = (1 + e^{-z_i})^{-1}$$\n",
    "\n",
    "Используем правило дифференцирования степенной функции и сложной функции:\n",
    "\n",
    "1. Берем производную внешней части (степени -1):\n",
    "\n",
    "$$-(1 + e^{-z_i})^{-2}$$\n",
    "\n",
    "2. Умножаем на производную внутренней части ($1 + e^{-z_i}$):\n",
    "Производная $1$ равна $0$. Производная $e^{-z_i}$ равна $e^{-z_i} \\cdot (-1)$.\n",
    "\n",
    "$$-e^{-z_i}$$\n",
    "\n",
    "3. Перемножаем:\n",
    "\n",
    "$$\\frac{\\partial p_i}{\\partial z_i} = \\left( -(1 + e^{-z_i})^{-2} \\right) \\cdot \\left( -e^{-z_i} \\right) = \\frac{e^{-z_i}}{(1 + e^{-z_i})^2}$$\n",
    "\n",
    "4. Алгебраический трюк для упрощения: Разделим дробь на два множителя:\n",
    "\n",
    "$$= \\frac{1}{1 + e^{-z_i}} \\cdot \\frac{e^{-z_i}}{1 + e^{-z_i}}$$\n",
    "\n",
    "Первый множитель — это само $p_i$.\n",
    "Второй множитель можно представить как $\\frac{(1 + e^{-z_i}) - 1}{1 + e^{-z_i}} = 1 - \\frac{1}{1 + e^{-z_i}} = 1 - p_i$.\n",
    "\n",
    "Результат Шага 2:$$p_i (1 - p_i)$$\n",
    "\n",
    "Шаг 3. Производная линейной части по весам ($\\frac{\\partial z_i}{\\partial \\beta}$)\n",
    "\n",
    "Здесь все линейно:\n",
    "\n",
    "$$z_i = \\beta_0 + \\beta_1 x_i$$\n",
    "\n",
    "Дифференцируем по конкретному коэффициенту $\\beta$ (например, $\\beta_1$):\n",
    "Результат Шага 3: $$x_i$$\n",
    "\n",
    "Теперь подставляем результаты всех трех шагов в исходную формулу цепного правила:\n",
    "\n",
    "$$\\frac{\\partial LL_i}{\\partial \\beta} = \\underbrace{\\left[ \\frac{y_i - p_i}{p_i(1 - p_i)} \\right]}_{\\text{Шаг 1}} \\cdot \\underbrace{\\left[ p_i(1 - p_i) \\right]}_{\\text{Шаг 2}} \\cdot \\underbrace{\\left[ x_i \\right]}_{\\text{Шаг 3}}$$\n",
    "\n",
    "Знаменатель из первого шага $p_i(1 - p_i)$ и числитель из второго шага $p_i(1 - p_i)$ полностью сокращаются.\n",
    "\n",
    "Итог для одного наблюдения:\n",
    "\n",
    "$$(y_i - p_i) \\cdot x_i$$\n",
    "\n",
    "Итог для всей выборки (возвращаем сумму):\n",
    "\n",
    "$$\\frac{\\partial LL}{\\partial \\beta} = \\sum_{i=1}^{N} (y_i - p_i) x_i$$\n",
    "\n",
    "Мы получили производную. В этом месте начинают использовать градиентный подъем, чтобы найти максимум функции.\n",
    "\n",
    "Для этого нужно \"подкручивать\" беты и смотреть, куда двигается изменение нашей функции. Нам нужно, чтобы двигалось наверх. Вот как это можно записать:\n",
    "\n",
    "$$\\beta^{(t+1)} = \\beta^{(t)} + \\eta \\cdot \\frac{\\partial LL}{\\partial \\beta}$$\n",
    "\n",
    "Где:\n",
    "\n",
    "$\\beta^{(t)}$ — текущие значения коэффициентов;\n",
    "\n",
    "$\\eta$ (эта) — скорость обучения (learning rate). Маленькое число (например, 0.01), контролирующее длину шага, чтобы не «перепрыгнуть» через максимум;\n",
    "\n",
    "$\\frac{\\partial LL}{\\partial \\beta}$ — тот самый градиент $\\sum (y_i - p_i) x_i$, который мы только что вывели.\n",
    "\n",
    "Эту формулу менее формально можно записать так:\n",
    "\n",
    "$$\\text{Наклон} = \\sum (y_{факт} - p_{прогноз}) \\cdot x$$\n",
    "\n",
    "Если ошибка $(y-p)$ большая — наклон крутой, надо делать большой шаг.\n",
    "\n",
    "Если ошибка почти ноль — мы почти на вершине (плато).\n",
    "\n",
    "Чтобы применить эту формулу, мы берем любые случайные коэффициенты $\\beta$ (например, нули). Это наша начальная точка на склоне. С помощью этих бет считаем p-прогноз, смотрим насколько ошиблись, а затем \"подкручиваем\" беты:\n",
    "\n",
    "$$\\beta_{новая} = \\beta_{старая} + (\\text{Скорость} \\times \\text{Наклон})$$\n",
    "\n",
    "Мы делаем шаг, оказываемся в новой точке. Снова измеряем наклон. Снова делаем шаг. Мы повторяем это сотни или тысячи раз, пока наклон не станет равным нулю. Это значит, что мы на вершине.\n",
    "\n",
    "\n",
    "Вернемся к нашим данным и посмотрим, как это работает.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee4588b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10253 entries, 0 to 10252\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   average_rating      10253 non-null  float64\n",
      " 1   num_pages           10253 non-null  int64  \n",
      " 2   ratings_count       10253 non-null  int64  \n",
      " 3   text_reviews_count  10253 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 320.5 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.59</td>\n",
       "      <td>501</td>\n",
       "      <td>4597666</td>\n",
       "      <td>94265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.27</td>\n",
       "      <td>366</td>\n",
       "      <td>2530894</td>\n",
       "      <td>32871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.80</td>\n",
       "      <td>277</td>\n",
       "      <td>2457092</td>\n",
       "      <td>43499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_rating  num_pages  ratings_count  text_reviews_count\n",
       "0            3.59        501        4597666               94265\n",
       "1            4.27        366        2530894               32871\n",
       "2            3.80        277        2457092               43499"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = pd.read_csv('gd_clean_data.csv', on_bad_lines='skip')\n",
    "db = db.drop(['title', 'language_code', 'authors', 'editions_count', 'year', 'quarter'], axis=1)\n",
    "db.info()\n",
    "db.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ccd96d",
   "metadata": {},
   "source": [
    "Для логистической регрессии нужен дихотамический признак. Надо превратить **average_rating** в такой признак. Однако здесь есть одна сложность, которая видна из описания данных. Половина средних оценок выше  3.96 и ниже 3.96. Только 25% оценок больше 4.14. Таким образом, если признать хорошими оценками только 4 и 5, то могут возникнуть сложности. Поэтому здесь можно снизить планку для оценки хорошо.\n",
    "\n",
    "Итак, оценка хорошо - это будет оценка от 3.96. Плохая оценка будет ниже 3.96."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "998809ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Увеличиваем верхнюю границу > 5, чтобы включить 5.0 при полуоткрытом интервале\n",
    "bins = [0, 3.96, 5.1] \n",
    "\n",
    "groups_names = ['0', '1'] \n",
    "\n",
    "# right=False меняет интервалы на [a, b)\n",
    "# Класс 0: [0, 3.96) -> строго меньше 3.96\n",
    "# Класс 1: [3.96, 5.1) -> больше или равно 3.96\n",
    "db['rating_groups'] = pd.cut(db['average_rating'], bins, labels=groups_names, right=False).astype('int64')\n",
    "\n",
    "db = db.drop('average_rating', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c533bdbc",
   "metadata": {},
   "source": [
    "Проверим, сколько наблюдений содержит каждый класс. Классы должны быть примерно одинаковыми по количеству. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13a5d994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_groups\n",
       "1    0.507266\n",
       "0    0.492734\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['rating_groups'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e3f96c",
   "metadata": {},
   "source": [
    "Логистическую регрессию можно реализовать статистически, а можно через машинное обучение. Первое больше подходит для понимания, второе – для предсказаний. Начнем со статистического подхода. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5060d02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682300\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:          rating_groups   No. Observations:                10253\n",
      "Model:                          Logit   Df Residuals:                    10249\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 25 Dec 2025   Pseudo R-squ.:                 0.01550\n",
      "Time:                        12:23:04   Log-Likelihood:                -6995.6\n",
      "converged:                       True   LL-Null:                       -7105.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.749e-47\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept             -0.4341      0.039    -11.267      0.000      -0.510      -0.359\n",
      "num_pages              0.0013   9.96e-05     13.485      0.000       0.001       0.002\n",
      "ratings_count       5.068e-07   4.03e-07      1.258      0.208   -2.83e-07     1.3e-06\n",
      "text_reviews_count  7.225e-06   1.69e-05      0.428      0.668   -2.58e-05    4.03e-05\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "# вызываю и обучаю модель\n",
    "model0 = smf.logit('rating_groups ~ num_pages + ratings_count + text_reviews_count', \n",
    "                    data=db).fit() \n",
    "\n",
    "# вызов результата модели\n",
    "print(model0.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247c5803",
   "metadata": {},
   "source": [
    "Подобный вывод мы видели, когда разбирали линейную регрессию. Здесь у вертикали всего два этажа, их и посмотрим. Верхний этаж содержит служебную информацию слева, а справа - несколько полезных показателей. \n",
    "\n",
    "Возьмем Pseudo R-squ. Вот как считают этот показатель:\n",
    "\n",
    "$$R^2_{McFadden} = 1 - \\frac{\\ln L_{full}}{\\ln L_{null}}$$\n",
    "\n",
    "Видим, что это показатель показывает, насколько лучше наша модель предсказывает, чем обычное среднее значение. У нас получилось значение 0.01550, что крайне низко. Модель логистической регрессии делает предсказание не лучше, чем обычное среднее.\n",
    "\n",
    "На нижнем этаже мы видим коэффициенты при каждом признаке. Смотрим на P>|z|, если показатель не превышает 0.05, то принимаем результат. Мы видим, что только для num_pages коэффициент получен не случайно, то есть иметь связь с рейтингом. \n",
    "\n",
    "Перейдем к машинному обучению. \n",
    "\n",
    "Как и в случае с линейной регрессией, применение машинного обучения предполагает ответы на следующие вопросы:\n",
    "\n",
    "1) Какую модель выбрать? Логистическая регрессия.\n",
    "\n",
    "2) Как подготовить данные? Надо получить такие переменные, которые будут хорошо разделять зависимую переменную на 1 и 0. Для этого надо преобразовать имеющиеся переменные и получить новые. В рамках этого приведем количественные переменные к нормальному распределению и масштабируем данные. Категориальные данные закодируем. Как количественные, так и категориальные данные разобъем по группам.\n",
    "\n",
    "3) Какие параметры модели настраивать и как? Будем использовать решетчатый поиск с кросс-валидацией.\n",
    "\n",
    "4) Что будет оценкой качества модели? Точность, а также матрица ошибок.\n",
    "\n",
    "5) Как можно получить предсказания по новым данным?\n",
    "\n",
    "Порядок действий такой:\n",
    "\n",
    "1) разделим данные на тренировочный и тестовый наборы;\n",
    "\n",
    "2) обработаем переменные;\n",
    "\n",
    "3) зададим модель логистической регрессии;\n",
    "\n",
    "4) обучим модель с настройкой параметров и оценкой;\n",
    "\n",
    "5) выберим лучшую модель;\n",
    "\n",
    "6) применим для новых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f4f8754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.58      0.56      1516\n",
      "           1       0.55      0.50      0.52      1560\n",
      "\n",
      "    accuracy                           0.54      3076\n",
      "   macro avg       0.54      0.54      0.54      3076\n",
      "weighted avg       0.54      0.54      0.54      3076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Формируем X и y\n",
    "# Убедитесь, что в X остались только числовые признаки: num_pages, ratings_count, text_reviews_count\n",
    "X = db.drop('rating_groups', axis=1) \n",
    "y = db['rating_groups']\n",
    "\n",
    "# 2. Разбиение\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3. Обучение через Pipeline\n",
    "# Математическая необходимость: StandardScaler приводит каждый признак к mu=0 и sigma=1\n",
    "# Это делает функционал ошибки J(beta) изотропным, ускоряя сходимость L-BFGS.\n",
    "model = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    LogisticRegression(random_state=42, max_iter=1000)\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Результаты\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b12c1",
   "metadata": {},
   "source": [
    "Показатель accuracy дает только 54% угадываний. Вот как считается этот показатель:\n",
    "\n",
    "$$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "Где:\n",
    "\n",
    "$TP$ (True Positives): Истинно положительные (книги класса 1, угаданные как 1).\n",
    "\n",
    "$TN$ (True Negatives): Истинно отрицательные (книги класса 0, угаданные как 0).\n",
    "\n",
    "$FP$ (False Positives): Ложно положительные (ошибка I рода: класс 0 принят за 1).\n",
    "\n",
    "$FN$ (False Negatives): Ложно отрицательные (ошибка II рода: класс 1 принят за 0).\n",
    "\n",
    "В нашем случае общее количество объектов $N = 3076$. Модель угадала примерно $54\\%$ из них, то есть $(TP + TN) \\approx 1661$.\n",
    "\n",
    "Эти результаты можно и визуализировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9aea676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAHiCAYAAACgORugAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZ0pJREFUeJzt3XdYFFfbBvB7QXoVEBYUAUXBgj0x2NBYQIk9tmACivjZjcaCEexYolEjRo3RCBossSYSNcGCvSt2iaJYECSKNJU+3x++bBwpsrjFxfuXa67r3ZkzZ57dd5GH55w5IxEEQQARERERqZSWugMgIiIi+hAxCSMiIiJSAyZhRERERGrAJIyIiIhIDZiEEREREakBkzAiIiIiNWASRkRERKQGTMKIiIiI1KCSugMgIiKiii8rKws5OTlK6VtXVxf6+vpK6VuZmIQRERGRUmVlZcHAxBLIe6GU/qVSKe7evatxiRiTMCIiIlKqnJwcIO8F9Or6Atq6iu08PwdJ18ORk5PDJIyIiIioWJX0IVFwEiZINHd6u+ZGTkRERKTBWAkjIiIi1ZAAkEgU36eGYhJGREREqiHRerUpuk8NpbmRExEREWkwVsKIiIhINSQSJQxHau54JCthRERERGrAShgRERGpBueEiWhu5EREREQajJUwIiIiUg3OCRNhJYyIiIhIDVgJIyIiIhVRwpwwDa4nMQkjIiIi1eBwpIjmpo9EREREGoyVMCIiIlINLlEhormRExEREWkwVsKIiIhINTgnTISVMCIiIiI1YCWMiIiIVINzwkQ0N3IiIiIiDcZKGBFplJycHKSkpKCgoAB2dnbqDoeI5ME5YSKshBHRe+/cuXP44osvYGVlBT09Pdja2qJ3795qi2fEiBHo2LGj2q5fnMzMTAwZMgRSqRQSiQRff/21wq/h6OgIPz8/hferqWbMmAFJORKAp0+fwsjICHv27FFCVO+5wuFIRW8aSnMjJ3pNWFgYJBIJJBIJjh07VuS4IAiwt7eHRCLBZ599poYIqbx+//13tGrVCtevX0dISAiioqIQFRWFn376SS3x3L17F2vWrMG3335b5Fh6ejpmzpyJhg0bwtjYGAYGBqhfvz4mT56MR48eKTWuuXPnIiwsDMOHD8eGDRvw5ZdfKvV6qqSKn++5c+di165d7xhp2VhaWmLIkCEIDg5WyfXo/cXhSKpQ9PX1sXHjRrRq1Uq0//Dhw3j48CH09PTUFBmVR0pKCoYMGQJPT09s3boVurq66g4JP/zwA5ycnNCuXTvR/jt37qBDhw64f/8++vTpg6FDh0JXVxeXL1/G2rVrsXPnTvzzzz9Ki+vgwYP45JNPMH36dKVdIzY2Flpa6vvbXZk/33PnzsXnn3+OHj16lPmcoKAgBAYGlut6w4YNw7Jly3Dw4EF8+umn5epDI0kkSpiYz+FIovdCly5dsHXrVuTl5Yn2b9y4EU2bNoVUKlVTZFQe69atQ1ZWFsLCwt6LBCw3NxcRERHo27evaH9eXh569eqFx48fIzo6Gps2bcLIkSMREBCA0NBQ3LlzB3369FFqbMnJyTA3N1fqNfT09KCjo6PUa5Tmffn5fv78OQCgUqVK0NfXL1cfderUQf369REWFqbAyEjTMAmjCmXAgAF4+vQpoqKiZPtycnKwbds2fPHFF8Wes2jRIrRo0QKWlpYwMDBA06ZNsW3bNlGbwqGQkra2bdsCAKKjoyGRSLBlyxZ8++23kEqlMDIyQrdu3fDgwQNRn23btpWdV+js2bOyPt+8/qhRo4rE/tlnn8HR0VG07/Lly/Dz80ONGjWgr68PqVSKwYMH4+nTp6V9dDLJycnw9/eHjY0N9PX10bBhQ4SHh4vaxMfHQyKRYNGiRaL99evXL/KegoKCIJFIkJmZKXo/M2bMELVbuHCh6LMEgFOnTqFRo0aYO3cu7O3toaenh1q1amH+/PkoKCgQnZ+Xl4fZs2ejZs2a0NPTg6OjI7799ltkZ2eL2hU3r2no0KHQ19dHdHR0qZ/NsWPH8OTJE3To0EG0f/v27bh06RKmTp1apEoDAKampggJCRHt27p1K5o2bQoDAwNYWVlh4MCBSEhIELXx8/ODsbExEhIS0KNHDxgbG6NKlSqYMGEC8vPzAfz3nbt79y7+/PNP2fcnPj5eNowXHx8v6rfwnNff761bt9C7d29IpVLo6+ujWrVq6N+/P9LS0kr97AoTTAsLCxgaGuKTTz7Bn3/+Wez1fvvtN4SEhKBatWrQ19dH+/btcfv27VI/89cp8+f7+fPnCA8Pl31+he+zcN7X9evX8cUXX6By5cqy/4/fnBO2bt06SCQS/PLLL6L+586dC4lEUmQOWMeOHbF7924IglDmz0DjaUmUs2koDkdSheLo6Ah3d3ds2rQJnTt3BgDs3bsXaWlp6N+/P5YtW1bknB9++AHdunWDj48PcnJysHnzZvTp0weRkZHw9vYGAGzYsEHW/ujRo1i9ejWWLFkCKysrAICNjY2oz5CQEEgkEkyePBnJyclYunQpOnTogJiYGBgYGJQY/+TJk9/5M4iKisKdO3cwaNAgSKVSXLt2DatXr8a1a9dw6tSpUicSv3z5Em3btsXt27cxatQoODk5YevWrfDz80NqairGjh37zvEVJzU1FfPmzSuy/+nTpzh27BiOHTuGwYMHo2nTpjhw4ACmTJmC+Ph4rFq1StZ2yJAhCA8Px+eff45vvvkGp0+fxrx583Djxg3s3LmzxGtPnz4da9euxZYtW4okkG86ceIEJBIJGjduLNr/xx9/AECZ52GFhYVh0KBB+OijjzBv3jw8fvwYP/zwA44fP46LFy+KKlr5+fnw9PRE8+bNsWjRIuzfvx/ff/89atasieHDh6NOnTrYsGEDxo0bh2rVquGbb74BAFSpUqVMsQCvEhlPT09kZ2dj9OjRkEqlSEhIQGRkJFJTU2FmZlbseY8fP0aLFi3w4sULjBkzBpaWlggPD0e3bt2wbds29OzZU9R+/vz50NLSwoQJE5CWlobvvvsOPj4+OH36dJniVObP95AhQ/Dxxx9j6NChAICaNWuK+unTpw9q1aqFuXPnlpg0DRo0CDt27MD48ePRsWNH2Nvb48qVK5g5cyb8/f3RpUsXUfumTZtiyZIluHbtGurXr1+mz4AqGIGoAli3bp0AQDh79qywfPlywcTERHjx4oUgCILQp08foV27doIgCIKDg4Pg7e0tOrewXaGcnByhfv36wqefflrqte7evVvk2KFDhwQAQtWqVYX09HTZ/t9++00AIPzwww+yfR4eHoKHh4fs9Z49ewQAgpeXl/DmjyYAYeTIkUWu5+3tLTg4OJT6fgRBEDZt2iQAEI4cOVLseyq0dOlSAYDw66+/yvbl5OQI7u7ugrGxsew93b17VwAgLFy4UHR+vXr1RO9JEARh6tSpAgAhIyND9H6mT58uez1p0iTB2tpaaNq0qeh8Dw8PAYAwY8YMUZ9+fn4CAOHKlSuCIAhCTEyMAEAYMmSIqN2ECRMEAMLBgwdl+xwcHARfX19BEAThp59+EgAIoaGhpX4uhQYOHChYWloW2d+4cWPBzMysTH3k5OQI1tbWQv369YWXL1/K9kdGRgoAhGnTpsn2+fr6CgCEWbNmFble06ZNRfuK+26X9F0t/J4eOnRIEARBuHjxogBA2Lp1a6mxv/7ZCYIgfP311wIA4ejRo7J9GRkZgpOTk+Do6Cjk5+eLrlenTh0hOztb1vaHH34Q/f9YElX8fBsZGYneW6Hp06cLAIQBAwaUeOx1iYmJgoWFhdCxY0chOztbaNy4sVC9enUhLS2tyPknTpwQAAhbtmwp9f1XBGlpaQIAQa91kKDfbo5CN73WQQKAYj/j9x2HI6nC6du3L16+fInIyEhkZGQgMjKyxKEKAKLK1LNnz5CWlobWrVvjwoUL5Y7hq6++gomJiez1559/Dltb2xJvSRcEAVOmTEHv3r3RvHnzcl8XEL+frKwsPHnyBJ988gkAvPU97dmzB1KpFAMGDJDt09HRwZgxY5CZmYnDhw+/U2zFSUhIQGhoKIKDg2FsbFzkuLa2NsaNGyfaV1jtKRz2Kvxcx48fX2q71/3+++8YMWIEJk6cWOxQb3GePn2KypUrF9mfnp4u+v+7NOfOnUNycjJGjBghmk/k7e0NV1fXYmMdNmyY6HXr1q1x586dMl2vLAorXX/99RdevHhR5vP27NmDjz/+WDQEa2xsjKFDhyI+Ph7Xr18XtR80aJBobl/r1q0BQK73oq6f7zf/PyiJVCrFjz/+iKioKLRu3RoxMTH45ZdfYGpqWqRt4XfpyZMncsVCFQeTMKpwqlSpgg4dOmDjxo3YsWMH8vPz8fnnn5fYPjIyEp988gn09fVhYWGBKlWqYOXKlaK5MPKqVauW6LVEIoGzs3ORuTmFIiIicO3aNcydO7fc1yyUkpKCsWPHwsbGBgYGBqhSpQqcnJwA4K3v6d69e6hVq1aRO+Dq1KkjO65o06dPh52dHf7v//6vyDGJRAI7O7siv8BcXFygpaUl+zzv3bsHLS0tODs7i9pJpVKYm5sXiTsmJgYDBgxAfn4+UlJS5IpXKGYoytTUFBkZGWU6vzAWFxeXIsdcXV2LxKqvr19kaLFy5cp49uxZWUN+KycnJ4wfPx5r1qyBlZUVPD098eOPP5bp+1Lc+yjp+1K9enXR68IkRJ73oq6f78KfobLo378/vL29cebMGQQEBKB9+/bFtiv8LpVnrTGNVbhYq6I3DcUkjCqkL774Anv37sWqVavQuXPnEu8aO3r0KLp16wZ9fX2sWLECe/bsQVRUFL744guVTZbNyclBcHAw/P39Ubt27Xfur2/fvvj5558xbNgw7NixA3///Tf27dsHAEUms6vbjRs3EBYWhjlz5hR7111p8+eKU9ZfZpcuXULbtm2xaNEi/PLLL2+dkF/I0tKy2ITB1dUVaWlpRW6+UARtbe1yn1vS51E4qf9133//PS5fvoxvv/0WL1++xJgxY1CvXj08fPiw3Nd/U0nvRd6fNXX8fMvzXXz69CnOnTsHALh+/XqJP3eF36XCuaUfBC7WKqK5kROVomfPntDS0sKpU6dKHarYvn079PX18ddff2Hw4MHo3LlzkTvfyuPWrVui14Ig4Pbt20XuZASAFStWIDk5ucjdguXx7NkzHDhwAIGBgZg5cyZ69uyJjh07okaNGmU638HBAbdu3SryS+PmzZuy44o0ZcoUNGrUCP369Sv2uJOTEx49elSkyvTPP/+goKBA9nk6ODigoKCgyOf++PFjpKamFonbzc0NW7duxbhx42STsbOyst4ar6urq2xI63Vdu3YFAPz6669v7aMwltjY2CLHYmNjFfoZF1aaUlNTRftLqmi6ubkhKCgIR44cwdGjR5GQkCC6+eFNDg4Oxb4PZX1fCinj51uR1aiRI0ciIyMD8+bNw7Fjx7B06dJi2929exfAf5VD+vAwCaMKydjYGCtXrsSMGTNkvyCLo62tDYlEIqoMxMfHv/PK2evXrxclDtu2bUNiYqLsjq5CGRkZCAkJwbhx4xSyxlFhpeHNv/JL+iXwpi5duiApKQlbtmyR7cvLy0NoaCiMjY3h4eHxzjEWOnnyJH7//XfMnz+/xF+AXbp0QX5+PpYvXy7av3jxYgCQ3d1WeNfZm+/zzXaFmjRpAiMjI2hpaWHNmjWIj4/HrFmz3hqzu7s7BEHA+fPnRfs///xzuLm5ISQkBCdPnixyXkZGBqZOnQoAaNasGaytrbFq1SrR8hl79+7FjRs3isT6Lgrv8Dty5IhsX35+PlavXi1ql56eXmTtLTc3N2hpaRVZ4uN1Xbp0wZkzZ0Tv+fnz51i9ejUcHR1Rt25dRbyNIpTx821kZFQkWS2Pbdu2YcuWLZg/fz4CAwPRv39/BAUFFbtQ7/nz52FmZoZ69eq983U1BocjRbhEBVVYvr6+b23j7e2NxYsXw8vLC1988QWSk5Px448/wtnZGZcvXy73tS0sLNCqVSsMGjQIjx8/xtKlS+Hs7IyAgABRuwsXLsDKygqTJk16a5/379+XDSsW+vfff/Hy5Uvs27cPHh4eMDU1RZs2bfDdd98hNzcXVatWxd9//y37i/tthg4dip9++gl+fn44f/48HB0dsW3bNhw/fhxLly4tMvk8NjZWFFNmZia0tLRE+0qadP3333+jY8eOpVYeu3Tpgg4dOmDq1Km4e/cuGjVqhIMHD2L79u0YNmyY7Lb+hg0bwtfXF6tXr0Zqaio8PDxw5swZhIeHo0ePHkVWt39d4WOF5s+fj/79+6NBgwYltm3VqhUsLS2xf/9+0SrnOjo62LFjBzp06IA2bdqgb9++aNmyJXR0dHDt2jVs3LgRlStXRkhICHR0dLBgwQIMGjQIHh4eGDBggGyJCkdHxyI3IbyLevXq4ZNPPsGUKVOQkpICCwsLbN68uUjCdfDgQYwaNQp9+vRB7dq1kZeXhw0bNkBbW7vUZ3QGBgbKlosYM2YMLCwsEB4ejrt372L79u1KXV1f0T/fTZs2xf79+7F48WLY2dnByclJ7ptkkpOTMXz4cLRr1052s8fy5ctx6NAh+Pn54dixY6LPJCoqCl27dv2w5oSRCJMw+qB9+umnWLt2LebPn4+vv/4aTk5OWLBgAeLj498pCfv2229x+fJlzJs3DxkZGWjfvj1WrFgBQ0PDIm2nTp1a7J1Tb9q9ezd2795d7LHOnTvj7t27cHR0xMaNGzF69Gj8+OOPEAQBnTp1wt69e2FnZ/fWaxgYGCA6OhqBgYEIDw9Heno6XFxcsG7dumIf3LxmzRqsWbOm2HjeRiKRYP78+W9ts2vXLgQHB2PLli0ICwuDg4MD5s+fj4kTJxaJpUaNGggLC8POnTshlUoxZcqUMj3GJygoCNu2bcOQIUNw8uTJEucu6erqwsfHB1u3bi1yE4WzszNiYmKwZMkS7Ny5E7t27UJBQQGcnZ0xZMgQjBkzRtbWz88PhoaGmD9/PiZPngwjIyP07NkTCxYsUPiq9xEREfi///s/zJ8/H+bm5vD390e7du1EDyBv2LAhPD09sXv3biQkJMDQ0BANGzbE3r17ZXfWFsfGxgYnTpzA5MmTERoaiqysLDRo0AC7d+9WaEWvvOT5+V68eDGGDh2KoKAgvHz5Er6+vnInYcOHD0d2drZs0Vbg1TzC1atXo3v37li0aJHsD66bN2/i6tWrZa5SVxjKmMOlwXPCJIKqZh8TfQCio6PRrl07bN26tdQ7thQpPj4eTk5OsiSMlOvOnTtwdXXF3r17S7zrjehtvv76axw5cgTnz5//ICph6enpMDMzg167WZBUKt+jnkoi5GUh+9A0pKWllekP2veJ5qaPRERqUKNGDfj7+7+1ikdUkqdPn2LNmjWYM2fOB5GAiXBOmAiHI4k0nIGBATw9PeVezoHKb+XKleoOgTSYpaWl6Fmq9OFiEkak4WxsbIpM2Cciei9xTpgIkzAiBWrbtq3KFnklIiLNxiSMiIiIVEMZc7g4J4yIiIjobZTxmCEOR9IHqqCgAI8ePYKJicmHd5cPEVEFIggCMjIyYGdnp9SFduk/TMLonTx69Aj29vbqDoOIiBTkwYMHqFatmnI653CkCJMweieFj7HRresLibaumqMhUp770YvUHQKRUmWkp8PZyb7I48lIeZiE0TspHIKUaOsyCaMKTdNW4iYqL6VOLZFIlLBEheZWwjjoS0RERKQGrIQRERGRanCxVhHNjZyIiIhIg7ESRkRERKrBuyNFmIQRERGRanA4UkRzIyciIiLSYKyEERERkWpwOFKElTAiIiIiNWAljIiIiFSDc8JENDdyIiIiIg3GShgRERGpBueEibASRkRERB+M/Px8BAcHw8nJCQYGBqhZsyZmz54NQRBkbfz8/CCRSESbl5eXqJ+UlBT4+PjA1NQU5ubm8Pf3R2ZmplyxsBJGREREKlGY0Ci4U7maL1iwACtXrkR4eDjq1auHc+fOYdCgQTAzM8OYMWNk7by8vLBu3TrZaz09PVE/Pj4+SExMRFRUFHJzczFo0CAMHToUGzduLHMsTMKIiIhIJd6HJOzEiRPo3r07vL29AQCOjo7YtGkTzpw5I2qnp6cHqVRabB83btzAvn37cPbsWTRr1gwAEBoaii5dumDRokWws7MrUywcjiQiIqIPRosWLXDgwAH8888/AIBLly7h2LFj6Ny5s6hddHQ0rK2t4eLiguHDh+Pp06eyYydPnoS5ubksAQOADh06QEtLC6dPny5zLKyEERERkWpI/rcpuk8A6enpot16enpFhhABIDAwEOnp6XB1dYW2tjby8/MREhICHx8fWRsvLy/06tULTk5OiIuLw7fffovOnTvj5MmT0NbWRlJSEqytrUX9VqpUCRYWFkhKSipz6EzCiIiISOPZ29uLXk+fPh0zZswo0u63335DREQENm7ciHr16iEmJgZff/017Ozs4OvrCwDo37+/rL2bmxsaNGiAmjVrIjo6Gu3bt1dYzEzCiIiISCWUOSfswYMHMDU1le0urgoGABMnTkRgYKAs0XJzc8O9e/cwb948WRL2pho1asDKygq3b99G+/btIZVKkZycLGqTl5eHlJSUEueRFYdzwoiIiEjjmZqairaSkrAXL15AS0uc/mhra6OgoKDEvh8+fIinT5/C1tYWAODu7o7U1FScP39e1ubgwYMoKChA8+bNyxwzK2FERESkEu/D3ZFdu3ZFSEgIqlevjnr16uHixYtYvHgxBg8eDADIzMzEzJkz0bt3b0ilUsTFxWHSpElwdnaGp6cnAKBOnTrw8vJCQEAAVq1ahdzcXIwaNQr9+/cv852RAJMwIiIi+oCEhoYiODgYI0aMQHJyMuzs7PB///d/mDZtGoBXVbHLly8jPDwcqampsLOzQ6dOnTB79mxRdS0iIgKjRo1C+/btoaWlhd69e2PZsmVyxSIRXl8ilkhO6enpMDMzg55bACTauuoOh0hpnp1dru4QiJQqPT0dNpZmSEtLE82tUlTfZmZmMO61ChIdA4X2LeS+ROaOYUqJW9lYCSMiIiKVeB+GI98nnJhPREREpAashBEREZFqKHGxVk3EShgRERGRGrASRkRERCrBOWFirIQRERERqQErYURERKQSEgmUUAlTbHeqxEoYERERkRqwEkZEREQqIYES5oRpcCmMSRgRERGpBCfmi3E4koiIiEgNWAkjIiIi1eBirSKshBERERGpASthREREpBpKmBMmcE4YEREREcmDlTAiIiJSCWXcHan4JS9Uh5UwIiIiIjVgJYyIiIhUgpUwMSZhREREpBpcokKEw5FEREREasBKGBEREakEhyPFWAkjIiIiUgNWwoiIiEglWAkTYyWMiIiISA1YCSMiIiKVYCVMjJUwIiIiIjVgJYyIiIhUgpUwMSZhREREpBpcrFWEw5FEREREasBKGBEREakEhyPFWAkjIiIiUgNWwoiIiEglWAkTYyWMiIiISA1YCSMiIiKVYCVMjJUwIiIiIjVgJYyIiIhUg+uEiTAJIyIiIpXgcKQYhyOJiIiI1ICVMCIiIlIJVsLEWAkjIiIiUgNWwoiIiEglJFBCJUyDZ+azEkZERESkBqyEERERkUpwTpgYK2FEREREasBKGBEREakGF2sVYSWMiIiISA1YCSMiIiKV4JwwMSZhREREpBJMwsQ4HElERESkBqyEERERkUpIJK82RfepqVgJIyIiIlIDVsKIiIhIJV5VwhQ9J0yh3akUK2FEREREasBKGBEREamGEuaEcbFWIiIiIpILK2FERESkElwnTIxJGBEREakEl6gQ43AkERERkRqwEkZEREQqoaUlgZaWYktXgoL7UyVWwoiIiIjUgJUwIiIiUgnOCRNjJYyIiIhIDVgJU5EZM2Zg165diImJUfq1cnJyULduXaxfvx4tWrQo0zn79u1DYGAgLly4AC0t5uaqpKUlQeDQLujr9RGsLU2R9CQNGyNPY9HafbI2Rga6mD6qO7p4NICFmRHuPXqK1VsOY92OY7I2u1eNRaumtUR9r9t+DOPnb1bZeyEqzaPkVMwI/R37T17Dy6xcOFWzwo/TBqJxXQcAwPzVf2LH3xeQ8PgZdHS00ci1OoJGdEWz+o6yPhb9sg9/H7uGq/88hI5OJdw7tFBN74bKg0tUiL1Xv239/PzQo0cPtV3f0dFR9gUxNDSEm5sb1qxZI3c/EokEu3btEu2bMGECDhw4oKBIS7dq1So4OTmJErCUlBT4+PjA1NQU5ubm8Pf3R2Zmpuy4l5cXdHR0EBERoZIY6T9ff9URg3u3xqSFW9G87xzMCP0dY77sgKH9PGRt5ozrjfbudfF/09ajed85WLU5Gt9N7IPObdxEfYXtPA4XrymybXroLhW/G6Lipaa/gNeQxdCppIWtP4zAqS1TMefrXjA3NZS1qVndGt9N7IPjm77F3p/Ho7qdBXqNWo4nzzJkbXJz89GjQ2MM7t1aHW+DSKHeqyTsfTBr1iwkJibi6tWrGDhwIAICArB379537tfY2BiWlpYKiLB0giBg+fLl8Pf3F+338fHBtWvXEBUVhcjISBw5cgRDhw4VtfHz88OyZcuUHiOJfdygBvYcvoy/j1/Dg8QU/HEwBodO30TTeg6yNs0bOGHTn6dx/MItPEhMQfjO47h6KwFN6jqI+nqZlYPkpxmyLeN5lqrfDlGxloZHoapNZfw4/Us0recIh6pW+PSTOnCqVkXWpo/XR2jb3BWO1axQp6Yt5nzdCxnPs3Dt1iNZmyn/540RX3yKus526ngb9I4K54QpetNUGpWEHT58GB9//DH09PRga2uLwMBA5OXlAQAiIyNhbm6O/Px8AEBMTAwkEgkCAwNl5w8ZMgQDBw4s9RomJiaQSqWoUaMGJk+eDAsLC0RFRcmOnz17Fh07doSVlRXMzMzg4eGBCxcuyI47OjoCAHr27AmJRCJ7PWPGDDRq1EjWrrDqt2jRItja2sLS0hIjR45Ebm6urE1iYiK8vb1hYGAAJycnbNy4EY6Ojli6dGmJ8Z8/fx5xcXHw9vaW7btx4wb27duHNWvWoHnz5mjVqhVCQ0OxefNmPHr03z9uXbt2xblz5xAXF1fqZ0SKdebyHXh85IKa1a0BAPVrVcUnDWtg/4nrsjanL99F5zZusK1iBgBo1bQWala3xqHTN0R99fFqhttR83Fi87eYNrIbDPR0VPdGiEqx7+gVNK5THX6Ba1GrUyDa+MxH+M7jJbbPyc1D+M7jMDU2QP3aVVUYKSlT4WiTojdNpTFzwhISEtClSxf4+flh/fr1uHnzJgICAqCvr48ZM2agdevWyMjIwMWLF9GsWTMcPnwYVlZWiI6OlvVx+PBhTJ48uUzXKygowM6dO/Hs2TPo6urK9mdkZMDX1xehoaEQBAHff/89unTpglu3bsHExARnz56FtbU11q1bBy8vL2hra5d4jUOHDsHW1haHDh3C7du30a9fPzRq1AgBAQEAgK+++gpPnjxBdHQ0dHR0MH78eCQnJ5ca99GjR1G7dm2YmJjI9p08eRLm5uZo1qyZbF+HDh2gpaWF06dPo2fPngCA6tWrw8bGBkePHkXNmjXL9DnRu1sSHgUTY32c2RqE/AIB2loSzFkZia37zsnaTF64FUu/HYDre0KQm5ePgoICjA3ZhBMX/0uYt/11Dg8SU5D0bxrq1bLD9FHd4exgja8myT+kTqRo8QlP8Mv2oxjxxacYP6gTLly7h8Dvt0FXRxsDPvtE1m7f0SsYMnUdXmTlQmplip3LR8HS3FiNkRMpj8YkYStWrIC9vT2WL18OiUQCV1dXPHr0CJMnT8a0adNgZmaGRo0aITo6Gs2aNUN0dDTGjRuHmTNnIjMzE2lpabh9+zY8PDxKvc7kyZMRFBSE7Oxs5OXlwcLCAkOGDJEd//TTT0XtV69eDXNzcxw+fBifffYZqlR5VVo3NzeHVCot9VqVK1fG8uXLoa2tDVdXV3h7e+PAgQMICAjAzZs3sX//fpw9e1aWPK1Zswa1atUqtc979+7Bzk5cpk9KSoK1tbVoX6VKlWBhYYGkpCTRfjs7O9y7d6/E/rOzs5GdnS17nZ6eXmo89HY9OzRBH6+PEBAUjpt3EuFWuyrmjv8cif+mYfOfpwEAQ/t5oJmbIwaMX4UHiSlo0dgZCyf1RdKTNBw+EwsAoqrC9bhHSHqSjj9WjoFjVSvEJzxRy3sjKlRQIKBRneqYNrIbAKCBiz1u3EnEuh3HRElY62a1cSRiCp6mZmL9rhMY9O0v2L9uAqpYmJTUNWkQTswX05jhyBs3bsDd3V30Ybds2RKZmZl4+PAhAMDDwwPR0dEQBAFHjx5Fr169UKdOHRw7dgyHDx+GnZ3dW5OYiRMnIiYmBgcPHkTz5s2xZMkSODs7y44/fvwYAQEBqFWrFszMzGBqaorMzEzcv39f7vdUr149UaXM1tZWVumKjY1FpUqV0KRJE9lxZ2dnVK5cudQ+X758CX19fbljKWRgYIAXL16UeHzevHkwMzOTbfb29uW+Fr0ya2wPLA2Pwo6o87ge9whb9p7Fik0HMc6vIwBAX08HwSO6ImjJDuw7ehXXbj/Cz1uPYGfUBYwa2L7Efs9fjQcA1LCvUmIbIlWxsTKFaw3xH6a1HaV4mPRMtM/IQA817KvgIzcnhAb7oJK2Fjb8fkKVoRKpjMZUwsqibdu2+OWXX3Dp0iXo6OjA1dUVbdu2RXR0NJ49e/bWKhgAWFlZwdnZGc7Ozti6dSvc3NzQrFkz1K1bFwDg6+uLp0+f4ocffoCDgwP09PTg7u6OnJwcuePV0RHP15FIJCgoKJC7nzfjv3LlimifVCotMoyZl5eHlJSUItW6lJQUWTWvOFOmTMH48eNlr9PT05mIvSMDPd0i/78XFAjQkrz6G0mnkjZ0dSqhQBDeaFMArVL+AnSrXQ0A8PhJmoIjJpJf84Y1cOue+N+huPvJqCa1KPW8ggIBObl5ygyNVIiLtYppTCWsTp06OHnyJITXfhEdP34cJiYmqFbt1S+bwnlhS5YskSVchUlYdHQ02rZtK9c17e3t0a9fP0yZMkV0zTFjxqBLly6oV68e9PT08OSJeKhHR0dHdoNAebm4uCAvLw8XL16U7bt9+zaePXtWyllA48aNcfPmTdHn5O7ujtTUVJw/f1627+DBgygoKEDz5s1l+7KyshAXF4fGjRuX2L+enh5MTU1FG72bfceuYPwgT3RqWQ/2thbwbtsAI75ohz+jLwEAMp5n4dj5W5g1pgdaNqmF6naWGPBZc/Tr8rGsjWNVK0zw90JDV3vY21qgcxs3rJz5JY5fuIVrtx+VdnkilRgx4FOcu3IX36/7C3ce/Iut+84ifOdxDOnTBgDw/GU2Zv34B85euYv7iSmIuXEfo2b9isR/U9G9/X8jAg+SUnAl9iEeJj1DQUEBrsQ+xJXYh8h8kV3SpYneW+9dJSwtLa3IgqaWlpYYMWIEli5ditGjR2PUqFGIjY3F9OnTMX78eNniopUrV0aDBg0QERGB5cuXAwDatGmDvn37Ijc3t0yVsDeNHTsW9evXx7lz59CsWTPUqlULGzZsQLNmzZCeno6JEyfCwMBAdI6joyMOHDiAli1bQk9P761DiMVxdXVFhw4dMHToUKxcuRI6Ojr45ptvYGBgUOr4d7t27ZCZmYlr166hfv36AF4lsF5eXggICMCqVauQm5uLUaNGoX///qL5Y6dOnZJV9kh1Ji/cim+HfYZFk/vBqrIxkp6kIWzHcXy35r+lUfyn/oJpI7tj9WxfVDY1xIOkFMxZGYlftr9arDU3Lw9tP3bB8P7tYGigi4THz7D7YAwW/fKXut4WkUiTeg7YsDAAs378AwvX7IWDnSXmju+Nvp0/AgBoa2nhVvxjbP7zNJ6mPoeFmSEa13XAntXjUKemrayfeav+xKb/zZUEgDYD5wMAdq8ag1ZNa6v2TZHcJFDCnDBobinsvUvCoqOji1Ri/P39sWbNGuzZswcTJ05Ew4YNYWFhAX9/fwQFBYnaenh4ICYmRlb1srCwQN26dfH48WO4uLjIHU/dunXRqVMnTJs2DXv27MHatWsxdOhQNGnSBPb29pg7dy4mTJggOuf777/H+PHj8fPPP6Nq1aqIj4+X+7oAsH79evj7+6NNmzaQSqWYN28erl27VuqcL0tLS/Ts2RMRERGYN2+ebH9ERARGjRqF9u3bQ0tLC7179y6yJtimTZvg4+MDQ0PDN7slJcp8kY1vF2/Ht4u3l9gm+WkGRs36tcTjCY9T8dn//aCM8IgUxqu1G7xauxV7TF9PBxsWBry1jxUzvsSKGV8qOjQitZAIwhsTTei99fDhQ9jb22P//v1o377kCdmXL19Gx44dERcXB2Pjst3a/eTJE7i4uODcuXNwcnIqc0zp6ekwMzODnlsAJNq6bz+BSEM9O7tc3SEQKVV6ejpsLM2Qlpam8Kkmhb8rGkz5A9r6RgrtOz/rOS7P66aUuJXtvauE0X8OHjyIzMxMuLm5ITExEZMmTYKjoyPatGlT6nkNGjTAggULcPfuXbi5Ff9X55vi4+OxYsUKuRIwIiIieXCJCjEmYe+x3NxcfPvtt7hz5w5MTEzQokULREREFLmrsjh+fn5yXatZs2aixVyJiIhIuZiEvcc8PT3h6emp7jCIiIgUgktUiGnMEhVEREREFQkrYURERKQSnBMmxkoYERERkRowCSMiIiKVKJwTpuhNHvn5+QgODoaTkxMMDAxQs2ZNzJ49W/SkGUEQMG3aNNja2sLAwAAdOnTArVu3RP2kpKTAx8cHpqamMDc3h7+/PzIzM+WKhUkYERERfTAWLFiAlStXYvny5bhx4wYWLFiA7777DqGhobI23333HZYtW4ZVq1bh9OnTMDIygqenJ7KysmRtfHx8cO3aNURFRSEyMhJHjhzB0KFD5YqFc8KIiIhIJd6HOWEnTpxA9+7d4e3tDeDVowY3bdqEM2fOAHhVBVu6dCmCgoLQvXt3AK+eYGNjY4Ndu3ahf//+uHHjBvbt24ezZ8/KlncKDQ1Fly5dsGjRItEjAUvDShgRERGphjKGIuXM6Vq0aIEDBw7gn3/+AQBcunQJx44dQ+fOnQEAd+/eRVJSEjp06CA7x8zMDM2bN8fJkycBACdPnoS5ublofc0OHTpAS0sLp0+fRlmxEkZEREQaLz09XfRaT08Penp6RdoFBgYiPT0drq6u0NbWRn5+PkJCQuDj4wMASEpKAgDY2NiIzrOxsZEdS0pKgrW1teh4pUqVYGFhIWtTFqyEERERkUoUDkcqegMAe3t7mJmZybZ58+YVG8Nvv/2GiIgIbNy4ERcuXEB4eDgWLVqE8PBwVX4UAFgJIyIiogrgwYMHogd4F1cFA4CJEyciMDAQ/fv3BwC4ubnh3r17mDdvHnx9fSGVSgEAjx8/hq2trey8x48fo1GjRgAAqVSK5ORkUb95eXlISUmRnV8WrIQRERGRSihziQpTU1PRVlIS9uLFC2hpidMfbW1tFBQUAACcnJwglUpx4MAB2fH09HScPn0a7u7uAAB3d3ekpqbi/PnzsjYHDx5EQUEBmjdvXubPg5UwIiIi+mB07doVISEhqF69OurVq4eLFy9i8eLFGDx4MIBXQ6Zff/015syZg1q1asHJyQnBwcGws7NDjx49AAB16tSBl5cXAgICsGrVKuTm5mLUqFHo379/me+MBJiEERERkYq8D0tUhIaGIjg4GCNGjEBycjLs7Ozwf//3f5g2bZqszaRJk/D8+XMMHToUqampaNWqFfbt2wd9fX1Zm4iICIwaNQrt27eHlpYWevfujWXLlskXu/D6ErFEckpPT4eZmRn03AIg0dZVdzhESvPs7HJ1h0CkVOnp6bCxNENaWppobpWi+jYzM8PHs/aikr6RQvvOy3qOM9M6KyVuZWMljIiIiFSiPI8ZKkufmopJGBEREanE+zAc+T7h3ZFEREREasBKGBEREakEK2FirIQRERERqQErYURERKQSnJgvxkoYERERkRqwEkZEREQqwTlhYqyEEREREakBK2FERESkEpwTJsYkjIiIiFSCw5FiHI4kIiIiUgNWwoiIiEglJFDCcKRiu1MpVsKIiIiI1ICVMCIiIlIJLYkEWgouhSm6P1ViJYyIiIhIDVgJIyIiIpXgEhVirIQRERERqQErYURERKQSXCdMjEkYERERqYSW5NWm6D41FYcjiYiIiNSAlTAiIiJSDYkShg9ZCSMiIiIiebASRkRERCrBJSrEWAkjIiIiUgNWwoiIiEglJP/7T9F9aipWwoiIiIjUgJUwIiIiUgmuEybGJIyIiIhUgivmi3E4koiIiEgNWAkjIiIileASFWKshBERERGpASthREREpBJaEgm0FFy6UnR/qsRKGBEREZEasBJGREREKsE5YWKshBERERGpASthREREpBJcJ0yMlTAiIiIiNShTJeyPP/4oc4fdunUrdzBERERUcXFOmFiZkrAePXqUqTOJRIL8/Px3iYeIiIgqKC5RIVamJKygoEDZcRARERF9UN5pTlhWVpai4iAiIqIKTqKkTVPJnYTl5+dj9uzZqFq1KoyNjXHnzh0AQHBwMNauXavwAImIiIgqIrmTsJCQEISFheG7776Drq6ubH/9+vWxZs0ahQZHREREFUfhEhWK3jSV3EnY+vXrsXr1avj4+EBbW1u2v2HDhrh586ZCgyMiIiKqqORerDUhIQHOzs5F9hcUFCA3N1chQREREVHFoyV5tSm6T00ldyWsbt26OHr0aJH927ZtQ+PGjRUSFBEREVFFJ3clbNq0afD19UVCQgIKCgqwY8cOxMbGYv369YiMjFRGjERERFQB8LFFYnJXwrp3747du3dj//79MDIywrRp03Djxg3s3r0bHTt2VEaMREREVEEUrpqvqE2TlesB3q1bt0ZUVJSiYyEiIiL6YJQrCQOAc+fO4caNGwBezRNr2rSpwoIiIiKiiofDkWJyJ2EPHz7EgAEDcPz4cZibmwMAUlNT0aJFC2zevBnVqlVTdIxEREREFY7cc8KGDBmC3Nxc3LhxAykpKUhJScGNGzdQUFCAIUOGKCNGIiIiqgAKl6hQ9Kap5K6EHT58GCdOnICLi4tsn4uLC0JDQ9G6dWuFBkdERERUUcmdhNnb2xe7KGt+fj7s7OwUEhQRERFVPJwTJib3cOTChQsxevRonDt3Trbv3LlzGDt2LBYtWqTQ4IiIiIgqqjJVwipXrizKNJ8/f47mzZujUqVXp+fl5aFSpUoYPHgwevTooZRAiYiISLNJ/rcpuk9NVaYkbOnSpUoOg4iIiCo6LYkEWgoePlR0f6pUpiTM19dX2XEQERERfVDKvVgrAGRlZSEnJ0e0z9TU9J0CIiIioopJGY8a0uBCmPwT858/f45Ro0bB2toaRkZGqFy5smgjIiIioreTOwmbNGkSDh48iJUrV0JPTw9r1qzBzJkzYWdnh/Xr1ysjRiIiIqoACpeoUPSmqeQejty9ezfWr1+Ptm3bYtCgQWjdujWcnZ3h4OCAiIgI+Pj4KCNOIiIiogpF7kpYSkoKatSoAeDV/K+UlBQAQKtWrXDkyBHFRkdEREQVRuGcMEVvmkruJKxGjRq4e/cuAMDV1RW//fYbgFcVssIHehMRERFR6eQejhw0aBAuXboEDw8PBAYGomvXrli+fDlyc3OxePFiZcRIREREFQDXCROTOwkbN26c7H936NABN2/exPnz5+Hs7IwGDRooNDgiIiKqOLhEhdg7rRMGAA4ODnBwcFBELEREREQfjDIlYcuWLStzh2PGjCl3MERERFRxKWNJiQq/RMWSJUvK1JlEImES9oFq5dsflQyM1B0GkdJ8ueGCukMgUqrcl5nqDuGDU6YkrPBuSCIiIqLy0kI5lmUoQ5+aSpNjJyIiItJY7zwxn4iIiKgsOCdMjJUwIiIiIjVgJYyIiIhUQiIBtLhOmAyTMCIiIlIJLSUkYYruT5XKNRx59OhRDBw4EO7u7khISAAAbNiwAceOHVNocEREREQVldxJ2Pbt2+Hp6QkDAwNcvHgR2dnZAIC0tDTMnTtX4QESERFRxVA4MV/Rm6aSOwmbM2cOVq1ahZ9//hk6Ojqy/S1btsSFC1zMkIiIiKgs5J4TFhsbizZt2hTZb2ZmhtTUVEXERERERBUQ54SJyV0Jk0qluH37dpH9x44dQ40aNRQSFBEREZEyODo6FjukOXLkSABA27ZtixwbNmyYqI/79+/D29sbhoaGsLa2xsSJE5GXlyd3LHJXwgICAjB27Fj88ssvkEgkePToEU6ePIkJEyYgODhY7gCIiIjowyCRKH5JCXn7O3v2LPLz82Wvr169io4dO6JPnz6yfQEBAZg1a5bstaGhoex/5+fnw9vbG1KpFCdOnEBiYiK++uor6OjoyD03Xu4kLDAwEAUFBWjfvj1evHiBNm3aQE9PDxMmTMDo0aPl7Y6IiIhIZapUqSJ6PX/+fNSsWRMeHh6yfYaGhpBKpcWe//fff+P69evYv38/bGxs0KhRI8yePRuTJ0/GjBkzoKurW+ZY5B6OlEgkmDp1KlJSUnD16lWcOnUK//77L2bPni1vV0RERPQB0ZJIlLKVV05ODn799VcMHjxYdJdlREQErKysUL9+fUyZMgUvXryQHTt58iTc3NxgY2Mj2+fp6Yn09HRcu3ZNruuXe7FWXV1d1K1bt7ynExER0QdGC4p/XmJhf+np6aL9enp60NPTK/XcXbt2ITU1FX5+frJ9X3zxBRwcHGBnZ4fLly9j8uTJiI2NxY4dOwAASUlJogQMgOx1UlKSXLHLnYS1a9eu1DU5Dh48KG+XRERERO/E3t5e9Hr69OmYMWNGqeesXbsWnTt3hp2dnWzf0KFDZf/bzc0Ntra2aN++PeLi4lCzZk2Fxix3EtaoUSPR69zcXMTExODq1avw9fVVVFxERERUwShzYv6DBw9gamoq2/+2Kti9e/ewf/9+WYWrJM2bNwcA3L59GzVr1oRUKsWZM2dEbR4/fgwAJc4jK4ncSdiSJUuK3T9jxgxkZmbK2x0RERHROzM1NRUlYW+zbt06WFtbw9vbu9R2MTExAABbW1sAgLu7O0JCQpCcnAxra2sAQFRUFExNTeWepqWwodmBAwfil19+UVR3REREVMFoQQkT8yF/aa2goADr1q2Dr68vKlX6rx4VFxeH2bNn4/z584iPj8cff/yBr776Cm3atEGDBg0AAJ06dULdunXx5Zdf4tKlS/jrr78QFBSEkSNHvrX69qZyT8x/08mTJ6Gvr6+o7oiIiIiUYv/+/bh//z4GDx4s2q+rq4v9+/dj6dKleP78Oezt7dG7d28EBQXJ2mhrayMyMhLDhw+Hu7s7jIyM4OvrK1pXrKzkTsJ69eolei0IAhITE3Hu3Dku1kpEREQleh8WawVeVbMEQSiy397eHocPH37r+Q4ODtizZ4/8F36D3EmYmZmZ6LWWlhZcXFwwa9YsdOrU6Z0DIiIiIvoQyJWE5efnY9CgQXBzc0PlypWVFRMRERFVQHyAt5hcE/O1tbXRqVMnpKamKikcIiIiqqgkEsWvmq/o4U1VkvvuyPr16+POnTvKiIWIiIjogyF3EjZnzhxMmDABkZGRSExMRHp6umgjIiIiKk7hxHxFb5qqzHPCZs2ahW+++QZdunQBAHTr1k30+CJBECCRSJCfn6/4KImIiIgqmDInYTNnzsSwYcNw6NAhZcZDREREFRQn5ouVOQkrXE/Dw8NDacEQERERfSjkWqJCoskDr0RERKRWkv/9p+g+NZVcSVjt2rXfmoilpKS8U0BEREREHwK5krCZM2cWWTGfiIiIqCw4J0xMriSsf//+sLa2VlYsREREVIExCRMr8zphnA9GREREpDhy3x1JREREVB4SiUThRR1NLhKVOQkrKChQZhxEREREHxS55oQRERERlRfnhInJ/exIIiIiInp3rIQRERGRSijjgdsaPCWMlTAiIiIidWAljIiIiFRCSyKBloJLV4ruT5VYCSMiIiJSA1bCiIiISCV4d6QYkzAiIiJSDSVMzIcGJ2EcjiQiIiJSA1bCiIiISCW0IIGWgktXiu5PlVgJIyIiIlIDVsKIiIhIJbhYqxgrYURERERqwEoYERERqQSXqBBjJYyIiIhIDVgJIyIiIpXgY4vEmIQRERGRSnBivhiHI4mIiIjUgJUwIiIiUgktKGE4kou1EhEREZE8WAkjIiIileCcMDFWwoiIiIjUgJUwIiIiUgktKL76o8nVJE2OnYiIiEhjsRJGREREKiGRSCBR8CQuRfenSkzCiIiISCUk/9sU3aem4nAkERERkRqwEkZEREQqwWdHirESRkRERKQGrIQRERGRymhu3UrxWAkjIiIiUgNWwoiIiEgl+NgiMVbCiIiIiNSAlTAiIiJSCS7WKsYkjIiIiFSCz44U0+TYiYiIiDQWK2FERESkEhyOFGMljIiIiEgNWAkjIiIileADvMVYCSMiIiJSA1bCiIiISCU4J0yMlTAiIiIiNWAljIiIiFSC64SJMQkjIiIileBwpJgmJ5BEREREGouVMCIiIlIJLlEhxkoYERERkRqwEkZEREQqIZG82hTdp6ZiJYyIiIhIDVgJIyIiIpXQggRaCp7Fpej+VImVMCIiIiI10IhKWFhYGL7++mukpqaW+Rw/Pz+kpqZi165dSotLXhKJBDt37kSPHj2Ufq21a9diy5Yt+Pvvv8t8Tv/+/fHRRx/hm2++UWJkVJzVAxrB2kSvyP491x5j9fF4mBvowO+T6mhY1RQGOtpISMvCtosJOHn3Wal9rD99HzsuJSo9fqKyWNyzHqoYF/2e74/9F39ee4wlveoXe17o4Ts4cz8VALDhyyZFjv949C5OxT8rsp/eP5wTJqbWJKykRCk6Ohrt2rXDs2fPYG5ujn79+qFLly5KjycsLAyDBg0C8CphsrGxQZs2bbBw4UJUr169zP3MmDEDu3btQkxMjGh/YmIiKleurMiQi5WVlYXg4GBs3bpVtu/atWuYNm0azp8/j3v37mHJkiX4+uuvRecFBQWhTZs2GDJkCMzMzJQeJ/1nws6r0HrtX5LqFgaY5V0HJ+48BQB83a4mDHW1Mfevf5CelYc2zpaY0L4WJuy8irtPX8jO23j2Af6++a/s9cvcfNW9CaK3mL4nFlqv/cKsZm6AwI61cPreMzx9kYNRWy+L2rerZYUu9Wxw6VG6aP/q4/G4/Nq+Fzn8nmsKyf/+U3SfmkojhiMNDAxgbW2tkmuZmpoiMTERCQkJ2L59O2JjY9GnTx+F9C2VSqGnV/SvQEXbtm0bTE1N0bJlS9m+Fy9eoEaNGpg/fz6kUmmx59WvXx81a9bEr7/+qvQYSSw9Kw+pL3Nl20fVzZGYloWriRkAABcbY+y59hi3/n2OxxnZ2HrxEZ7n5KGmlZGon5e5BaJ+svMK1PF2iIqVkZ2HtKz/tkbVzPA4PQs3H2dCECA6lpaVh6bVzXHm3rMi3+MXufmidrkFgpreEdG70YgkLCwsDObm5qJ9c+bMgbW1NUxMTDBkyBAEBgaiUaNGRc5dtGgRbG1tYWlpiZEjRyI3N7fUa0kkEkilUtja2qJFixbw9/fHmTNnkJ7+319dkydPRu3atWFoaIgaNWogODhY1m9YWBhmzpyJS5cuyR7PEBYWJuu7sOoXHx8PiUSCHTt2oF27djA0NETDhg1x8uRJUTw///wz7O3tYWhoiJ49e2Lx4sVFPos3bd68GV27dhXt++ijj7Bw4UL079+/1ESwa9eu2Lx5c6n9k3JV0pLAo5YVDsT+V9GKfZyJljUsYKynDQmAVjUtoKuthauJ4gpBr0a2WP9VEyzuVR89GtiKqg5E7xNtLQlaOlngcNzTYo87WhjA0cIQh28XPf7Vx/ZY0acBZnR2QZualsoOlRSocDhS0Zum0og5YW+KiIhASEgIVqxYgZYtW2Lz5s34/vvv4eTkJGp36NAh2Nra4tChQ7h9+zb69euHRo0aISAgoEzXSU5Oxs6dO6GtrQ1tbW3ZfhMTE4SFhcHOzg5XrlxBQEAATExMMGnSJPTr1w9Xr17Fvn37sH//fgAodWhv6tSpWLRoEWrVqoWpU6diwIABuH37NipVqoTjx49j2LBhWLBgAbp164b9+/cjODj4rXEfO3YMX375ZZne45s+/vhjhISEIDs7WyVVOyqquWNlGOlWwoF//kvCFu6/hQntnfGrbzPkFRQgO68A8/++haT0bFmbyKtJuPPkOTKy8+BqY4IvP7ZHZUMdrDt1Xx1vg6hUTe3NYKirjaNxKcUe93C2QkLqS9z697lo/7aYR7ielIGcvALUtzOFb3N76OtoiYbhiTSF2pOwyMhIGBsbi/bl55c+vh8aGgp/f3/Z/K1p06bh77//RmZmpqhd5cqVsXz5cmhra8PV1RXe3t44cOBAqUlYWloajI2NIQgCXrx4NddmzJgxMDL6b9gnKChI9r8dHR0xYcIEbN68GZMmTYKBgQGMjY1RqVKlEof9XjdhwgR4e3sDAGbOnIl69erh9u3bcHV1RWhoKDp37owJEyYAAGrXro0TJ04gMjKyxP5SU1ORlpYGOzu7t167OHZ2dsjJyUFSUhIcHByKHM/OzkZ29n+/+F+vEJJidHCpggsPUvHsxX9V2y+aVYORXiVMi7yB9Kw8NHesjIkdnPHtH9dx79lLAMAfV5Jk7e+lvERegYDhrR2x4cwD5HG4ht4zHs5WuPwoHakvi45O6GhL4O5UGb9fTipy7PfXv+fPXkKvkha61LVhEqYhJEpYooJzwt5Bu3btEBMTI9rWrFlT6jmxsbH4+OOPRfvefA0A9erVE1WwbG1tkZycXGrfJiYmiImJwblz5/D999+jSZMmCAkJEbXZsmULWrZsCalUCmNjYwQFBeH+/fJVGxo0aCCKD4AsxrK+z9e9fPnqF7K+vn654jEwMAAAWQL6pnnz5sHMzEy22dvbl+s6VLwqxrpoUNUMUa/9QpGa6MG7vhShh+/g8qN0xKe8wJYLCbj973N0rmdTYl//JGeikpZWsXddEqmTpZEu6ktNEH3rSbHHP65eGXraWjh2p/gq2evinjyHpZEuKnHsnTSQ2pMwIyMjODs7i7aqVasqpG8dHR3Ra4lEgoKC0icqa2lpwdnZGXXq1MH48ePxySefYPjw4bLjJ0+ehI+PD7p06YLIyEhcvHgRU6dORU5OzjvHKPnfwPbbYiyNpaUlJBIJnj0r3+3aKSmv/tGrUqVKscenTJmCtLQ02fbgwYNyx0pFtXepgrSsXJy7/9//f3qVXv2YCoK4mlUgCKI7Kt/kZGmI/AIBacVUGojUqU1NS6Rn5SEmIa3Y4x7OlrjwMA0Z2Xlv7cuhsiEys/NY7dUQnBMmpvYkrDxcXFxw9uxZ0b43XytKYGAgtmzZggsXLgAATpw4AQcHB0ydOhXNmjVDrVq1cO/ePdE5urq6bx1SLYvyvE9dXV3UrVsX169fL9c1r169imrVqsHKyqrY43p6ejA1NRVtpBgSAJ/WroJD/zzB679PHqZm4VFaFoa3dkKtKkaQmuihu5sUDauZ4XT8q6TZxdoYXetL4WhhCBsTPbRxtsRgdwccvv0Ez3n7Pr1HJADa1LTA0TtPUVzeZG2iBxcbY0QXMyG/cTUzeDhbopq5PqxN9NC+thW6udmIKsdEmkTtc8LKY/To0QgICECzZs3QokULbNmyBZcvX0aNGjUUfi17e3v07NkT06ZNQ2RkJGrVqoX79+9j8+bN+Oijj/Dnn39i586donMcHR1x9+5dxMTEoFq1ajAxMSnXJPfRo0ejTZs2WLx4Mbp27YqDBw9i7969sopZSTw9PXHs2DHROmA5OTmyxCwnJwcJCQmIiYmBsbExnJ2dZe2OHj2KTp06yR0rvbuGVc1gbaInuisSAPIFAbP33sRXzatjqqcL9HW0kJiehWXRd3D+watKQm5+AVrVtET/plVRSVsLyRnZ2H0lCb9f5kKt9H6pZ2sCK2M9HCkmyQIAj5qWSHmRi6uPis43zSsQ0MGlCnyaVYMEwOOMbEScSyhxWJPeP1ysVUwjkzAfHx/cuXMHEyZMQFZWFvr27Qs/Pz+cOXNGKdcbN24c3N3dcebMGXTr1g3jxo3DqFGjkJ2dDW9vbwQHB2PGjBmy9r1795YtPZGamop169bBz89P7uu2bNkSq1atwsyZMxEUFARPT0+MGzcOy5cvL/U8f39/NGvWDGlpabI7Mx89eoTGjRvL2ixatAiLFi2Ch4cHoqOjAbxa5HXXrl3Yt2+f3LHSu4tJSEOP1aeLPZaYno0FUbdKPPfO0xeY/Ps1ZYVGpDBXEzPw5YYLJR7fGvMIW2MeFXvsyqN0XCkmOSPNwcVaxSTCmxNNNFTHjh0hlUqxYcMGdYeiVAEBAbh58yaOHj1aars+ffqgSZMmmDJlSpn7XrlyJXbu3CnXo47S09NhZmaG9osOoJKB0dtPINJQJgY6b29EpMFyX2bi95EeSEtLU/hUk8LfFTvP3IGRsYlC+36emYGeH9dQStzKppGVsBcvXmDVqlXw9PSEtrY2Nm3ahP379yMqKkrdoSncokWL0LFjRxgZGWHv3r0IDw/HihUr3nrewoULsXv3brmupaOjg9DQ0PKGSkREVCotCRS+iLQm3xirkUmYRCLBnj17EBISgqysLLi4uGD79u3o0KGDukNTuDNnzuC7775DRkYGatSogWXLlmHIkCFvPc/R0RGjR4+W61pl6ZeIiIgUQyPvjjQwMMD+/fvx9OlTPH/+HBcuXECvXr3UHZZS/Pbbb0hOTsbLly9x7do1DBs2TN0hERERlYtESf/Jw9HRUfZYwde3kSNHAng1P3rkyJGwtLSEsbExevfujcePH4v6uH//Pry9vWFoaAhra2tMnDgReXlvX1LlTRqZhBERERGVx9mzZ5GYmCjbCqcy9enTB8Crm/F2796NrVu34vDhw3j06JGo0JOfnw9vb2/k5OTgxIkTCA8PR1hYGKZNmyZ3LBo5HElERESa531YouLNxcjnz5+PmjVrwsPj1U0Ja9euxcaNG/Hpp58CANatW4c6derg1KlT+OSTT/D333/j+vXr2L9/P2xsbNCoUSPMnj0bkydPxowZM6Crq1vmWFgJIyIiIo2Xnp4u2l5/znFJcnJy8Ouvv2Lw4MGQSCQ4f/48cnNzRXPMXV1dUb16dZw8eRLAqyfnuLm5wcbmv8fGeXp6Ij09HdeuybdUEJMwIiIiUgkJlDEv7BV7e3vRs43nzZv31nh27dqF1NRU2VqeSUlJ0NXVhbm5uaidjY0NkpKSZG1eT8AKjxcekweHI4mIiEgllLlExYMHD0TrhJXlSTVr165F586dYWdnp9igyohJGBEREWk8eZ9nfO/ePezfvx87duyQ7ZNKpcjJyUFqaqqoGvb48WNIpVJZmzef0FN492Rhm7LicCQRERGpxPuwREWhdevWwdraGt7e3rJ9TZs2hY6ODg4cOCDbFxsbi/v378Pd3R0A4O7ujitXriA5OVnWJioqCqampqhbt65cMbASRkRERB+UgoICrFu3Dr6+vqhU6b9UyMzMDP7+/hg/fjwsLCxgamqK0aNHw93dHZ988gkAoFOnTqhbty6+/PJLfPfdd0hKSkJQUBBGjhxZpiHQ1zEJIyIiIpV4H5aoAID9+/fj/v37GDx4cJFjS5YsgZaWFnr37o3s7Gx4enqKHheora2NyMhIDB8+HO7u7jAyMoKvry9mzZoldxxMwoiIiOiD0qlTJwiCUOwxfX19/Pjjj/jxxx9LPN/BwQF79ux55ziYhBEREZFKSP63KbpPTcWJ+URERERqwEoYERERqYQWJNBS8KQwLQ2uhbESRkRERKQGrIQRERGRSnBOmBiTMCIiIlINZmEiHI4kIiIiUgNWwoiIiEgl3uUxQ6X1qalYCSMiIiJSA1bCiIiISDWU8NgiDS6EsRJGREREpA6shBEREZFK8OZIMVbCiIiIiNSAlTAiIiJSDZbCRJiEERERkUpwiQoxDkcSERERqQErYURERKQSEiUsUaHwJS9UiJUwIiIiIjVgJYyIiIhUgvPyxVgJIyIiIlIDVsKIiIhINVgKE2EljIiIiEgNWAkjIiIileA6YWJMwoiIiEgluESFGIcjiYiIiNSAlTAiIiJSCc7LF2MljIiIiEgNWAkjIiIi1WApTISVMCIiIiI1YCWMiIiIVIJLVIixEkZERESkBqyEERERkUpwnTAxJmFERESkEpyXL8bhSCIiIiI1YCWMiIiIVIOlMBFWwoiIiIjUgJUwIiIiUgkuUSHGShgRERGRGrASRkRERCrBJSrEWAkjIiIiUgNWwoiIiEgleHOkGJMwIiIiUg1mYSIcjiQiIiJSA1bCiIiISCW4RIUYK2FEREREasBKGBEREakEl6gQYyWMiIiISA1YCSMiIiKV4M2RYqyEEREREakBK2FERESkGiyFiTAJIyIiIpXgEhViHI4kIiIiUgNWwoiIiEg1lLBEhQYXwlgJIyIiIlIHVsKIiIhIJTgvX4yVMCIiIiI1YCWMiIiIVIOlMBFWwoiIiIjUgJUwIiIiUgmuEybGJIyIiIhUQqKEJSoUvuSFCnE4koiIiEgNWAkjIiIileC8fDFWwoiIiIjUgJUwIiIiUg2WwkRYCSMiIiJSA1bCiIiISCW4RIUYK2FEREREasBKGBEREamEBEpYJ0yx3akUkzAiIiJSCc7LF+NwJBEREZEasBJGREREKsHHFomxEkZERESkBqyEERERkYpwVtjrmITROxEEAQCQl/VczZEQKVcu/7mkCi735at/xwv/XSfl478q9E4yMjIAAIeDuqk5EiIiUoSMjAyYmZkppW/OCRNjEkbvxM7ODg8ePICJiQkkmvyToEHS09Nhb2+PBw8ewNTUVN3hECkFv+eqJwgCMjIyYGdnp+5QPhhMwuidaGlpoVq1auoO44NkamrKX05U4fF7rlrKqoAV4owwMSZhREREpBIcjhTjEhVEREREasBKGJGG0dPTw/Tp06Gnp6fuUIiUht/ziknyv/8U3aemYiWMSMPo6elhxowZ/OVEFRq/56RMCQkJGDhwICwtLWFgYAA3NzecO3dOdtzPzw8SiUS0eXl5ifpISUmBj48PTE1NYW5uDn9/f2RmZsoVBythREREpBrvwcz8Z8+eoWXLlmjXrh327t2LKlWq4NatW6hcubKonZeXF9atWyd7/eYfBD4+PkhMTERUVBRyc3MxaNAgDB06FBs3bixzLEzCiIiI6IOxYMEC2NvbixIsJyenIu309PQglUqL7ePGjRvYt28fzp49i2bNmgEAQkND0aVLFyxatKjMy3xwOJKIiIhUQqKkDXi1ttzrW3Z2drEx/PHHH2jWrBn69OkDa2trNG7cGD///HORdtHR0bC2toaLiwuGDx+Op0+fyo6dPHkS5ubmsgQMADp06AAtLS2cPn26zJ8HkzCiCmLGjBlo1KiRSq6Vk5MDZ2dnnDhxoszn7Nu3D40aNUJBQYESI6OyCAsLg7m5uVzn+Pn5oUePHkqJp7wkEgl27dqlkmutXbsWnTp1kuuc/v374/vvv1dSRPQme3t7mJmZybZ58+YV2+7OnTtYuXIlatWqhb/++gvDhw/HmDFjEB4eLmvj5eWF9evX48CBA1iwYAEOHz6Mzp07Iz8/HwCQlJQEa2trUb+VKlWChYUFkpKSyhwzkzD6oKj7F4mjo6NskqehoSHc3NywZs0aufsp7pfPhAkTcODAAQVFWrpVq1bByckJLVq0kO172yRVLy8v6OjoICIiQiUxfohK+n5HR0dDIpEgNTUVANCvXz/8888/So8nLCxM9n3X0tKCra0t+vXrh/v378vVT0l/YCQmJqJz584KirZkWVlZCA4OxvTp02X7rl27ht69e8t+ppcuXVrkvKCgIISEhCAtLU3pMWqKwnXCFL0BwIMHD5CWlibbpkyZUmwMBQUFaNKkCebOnYvGjRtj6NChCAgIwKpVq2Rt+vfvj27dusHNzQ09evRAZGQkzp49i+joaIV+HkzCiFRs1qxZSExMxNWrVzFw4EAEBARg796979yvsbExLC0tFRBh6QRBwPLly+Hv7y/a7+Pjg2vXriEqKgqRkZE4cuQIhg4dKmrj5+eHZcuWKT1GKp2BgUGRv+KVxdTUFImJiUhISMD27dsRGxuLPn36KKRvqVSqkrsnt23bBlNTU7Rs2VK278WLF6hRowbmz59f4ryh+vXro2bNmvj111+VHiP993SFwq2k74atrS3q1q0r2lenTp1S/zioUaMGrKyscPv2bQCvvnvJycmiNnl5eUhJSSnx+1AcJmFErzl8+DA+/vhj6OnpwdbWFoGBgcjLywMAREZGwtzcXFaOjomJgUQiQWBgoOz8IUOGYODAgaVew8TEBFKpFDVq1MDkyZNhYWGBqKgo2fGzZ8+iY8eOsLKygpmZGTw8PHDhwgXZcUdHRwBAz549IZFIZK/frBYUVkUWLVoEW1tbWFpaYuTIkcjNzZW1SUxMhLe3NwwMDODk5ISNGzfC0dGx2L/qC50/fx5xcXHw9vaW7SucpLpmzRo0b94crVq1QmhoKDZv3oxHjx7J2nXt2hXnzp1DXFxcqZ8RKVdxw5Fz5syBtbU1TExMMGTIEAQGBhZbfSrt+1QciUQCqVQKW1tbtGjRAv7+/jhz5gzS09NlbSZPnozatWvD0NAQNWrUQHBwsKzfsLAwzJw5E5cuXZJV1cLCwmR9F1aE4+PjIZFIsGPHDrRr1w6GhoZo2LAhTp48KYrn559/hr29PQwNDdGzZ08sXrz4rUOzmzdvRteuXUX7PvroIyxcuBD9+/cvNRHs2rUrNm/eXGr/HxKJkv6TR8uWLREbGyva988//8DBwaHEcx4+fIinT5/C1tYWAODu7o7U1FScP39e1ubgwYMoKChA8+bNyxwLkzCi/0lISECXLl3w0Ucf4dKlS1i5ciXWrl2LOXPmAABat26NjIwMXLx4EcCrhM3KykpUnj58+DDatm1bpusVFBRg+/btePbsGXR1dWX7MzIy4Ovri2PHjuHUqVOoVasWunTpgoyMDACvkjQAWLduHRITE2Wvi3Po0CHExcXh0KFDCA8PR1hYmOwXGAB89dVXePToEaKjo7F9+3asXr26yF93bzp69Chq164NExMT2b6yTlKtXr06bGxscPTo0TJ9RqQaERERCAkJwYIFC3D+/HlUr14dK1euLNLubd+nt0lOTsbOnTuhra0NbW1t2X4TExOEhYXh+vXr+OGHH/Dzzz9jyZIlAF4NnX7zzTeoV68eEhMTkZiYiH79+pV4jalTp2LChAmIiYlB7dq1MWDAANkfUsePH8ewYcMwduxYxMTEoGPHjggJCXlr3MeOHRN9t+Xx8ccf48yZMyVOEv/gKHNmfhmNGzcOp06dwty5c3H79m1s3LgRq1evxsiRIwEAmZmZmDhxIk6dOoX4+HgcOHAA3bt3h7OzMzw9PQG8qpx5eXkhICAAZ86cwfHjxzFq1Cj0799fvgegC0QfEF9fX6F79+7FHvv2228FFxcXoaCgQLbvxx9/FIyNjYX8/HxBEAShSZMmwsKFCwVBEIQePXoIISEhgq6urpCRkSE8fPhQACD8888/JV7fwcFB0NXVFYyMjIRKlSoJAAQLCwvh1q1bJZ6Tn58vmJiYCLt375btAyDs3LlT1G769OlCw4YNRe/VwcFByMvLk+3r06eP0K9fP0EQBOHGjRsCAOHs2bOy47du3RIACEuWLCkxnrFjxwqffvqpaF9ISIhQu3btIm2rVKkirFixQrSvcePGwowZM0rsn8rP19dX0NbWFoyMjESbvr6+AEB49uyZIAiCsG7dOsHMzEx2XvPmzYWRI0eK+mrZsqVc36firFu3TgAgGBkZCYaGhgIAAYAwZsyYUt/HwoULhaZNm8pev/ndLvT6z8Hdu3cFAMKaNWtkx69duyYAEG7cuCEIgiD069dP8Pb2FvXh4+Mj+ize9OzZMwGAcOTIkRLbODg4lPgzc+nSJQGAEB8fX+L5H4K0tDQBgBCX8FRIzshV6BaX8FQAIKSlpZU5nt27dwv169cX9PT0BFdXV2H16tWyYy9evBA6deokVKlSRdDR0REcHByEgIAAISkpSdTH06dPhQEDBgjGxsaCqampMGjQICEjI0Ouz4XrhBH9z40bN+Du7g7Ja0+DbdmyJTIzM/Hw4UNUr14dHh4eiI6OxjfffIOjR49i3rx5+O2333Ds2DGkpKTAzs4OtWrVKvU6EydOhJ+fHxITEzFx4kSMGDECzs7OsuOPHz9GUFAQoqOjkZycjPz8fLx48ULuycwAUK9ePVHFwdbWFleuXAEAxMbGolKlSmjSpInsuLOzc5EFC9/08uVL6Ovryx1LIQMDA7x48aLc51Pp2rVrV6SKdfr06VKHyWNjYzFixAjRvo8//hgHDx4U7Svt+1QSExMTXLhwAbm5udi7d6+s6va6LVu2YNmyZYiLi0NmZiby8vJgampaar8ladCggSg+4FUFztXVFbGxsejZs2eR9xkZGVlify9fvgSAcn/nDQwMAIDf+f95D9ZqBQB89tln+Oyzz4o9ZmBggL/++uutfVhYWMi1MGtxmIQRyaFt27b45ZdfcOnSJejo6MDV1RVt27ZFdHQ0nj17Bg8Pj7f2YWVlBWdnZzg7O2Pr1q1wc3NDs2bNZBNFfX198fTpU/zwww9wcHCAnp4e3N3dkZOTI3e8Ojo6otcSieSdl4iwsrIq8otXnkmqKSkpqFKlyjvFQCUzMjISJfXAq/ksilCe75OWlpYsnjp16iAuLg7Dhw/Hhg0bALwayvbx8cHMmTPh6ekJMzMzbN68udxLO7weY+EfVO/ynbe0tIREIsGzZ8/KdX5KSgoA8DtPxeKcMKL/qVOnDk6ePAlBEGT7jh8/DhMTE1SrVg3Af/PClixZIku4CpOw6OjoMs8HK2Rvb49+/fqJbqU+fvw4xowZgy5duqBevXrQ09PDkydPROfp6OjIbhAoLxcXF+Tl5cnmuAHA7du33/rLpnHjxrh586bocyrrJNWsrCzExcWhcePG7xQ7KZaLi0uRuYWlzTV8F4GBgdiyZYvsZpMTJ07AwcEBU6dORbNmzVCrVi3cu3dPdI6uru47f9+B8r1PXV1d1K1bF9evXy/XNa9evYpq1arBysqqXOdXNMpcokITMQmjD05aWhpiYmJE24MHDzBixAg8ePAAo0ePxs2bN/H7779j+vTpGD9+PLS0Xv2oVK5cGQ0aNEBERIQs4WrTpg0uXLiAf/75p0yVsDeNHTsWu3fvlj08tlatWtiwYQNu3LiB06dPw8fHRzakUcjR0REHDhxAUlJSuf9Cd3V1RYcOHTB06FCcOXMGFy9exNChQ2FgYCAakn1Tu3btkJmZiWvXrsn2lXWS6qlTp2SVPXp/jB49GmvXrkV4eDhu3bqFOXPm4PLly6V+D8rL3t4ePXv2xLRp0wC8+r7fv38fmzdvRlxcHJYtW4adO3eKznF0dMTdu3cRExODJ0+elHuS++jRo7Fnzx4sXrwYt27dwk8//YS9e/e+9X16enri2LFjon05OTmyfz9ycnKQkJCAmJgY2RIGhY4ePSr3Iq/04WASRh+c6OhoNG7cWLTNnDkTVatWxZ49e3DmzBk0bNgQw4YNg7+/P4KCgkTne3h4ID8/X5aEWVhYoG7dupBKpXBxcZE7nrp166JTp06yX0pr167Fs2fP0KRJE3z55ZcYM2ZMkTWdvv/+e0RFRcHe3v6dqkrr16+HjY0N2rRpg549eyIgIAAmJialzn+xtLREz549iyy6GhERAVdXV7Rv3x5dunRBq1atsHr1alGbTZs2wcfHB4aGhuWOmRTPx8cHU6ZMwYQJE9CkSRPcvXsXfn5+7zT3rzTjxo3Dn3/+iTNnzqBbt24YN24cRo0ahUaNGuHEiRMIDg4Wte/duze8vLzQrl07VKlSBZs2bSrXdVu2bIlVq1Zh8eLFaNiwIfbt24dx48a99X36+/tjz549okVXHz16JPv3IzExEYsWLULjxo0xZMgQWZusrCzs2rULAQEB5Yq3YlLG8hSaWwqTCK+PKRDRB+3hw4ewt7fH/v370b59+xLbXb58GR07dkRcXByMjY3L1PeTJ0/g4uKCc+fOFfuwXHq/dOzYEVKpVDZ3q6IKCAjAzZs337psSp8+fdCkSZMSV2EvzsqVK7Fz5078/fff7xqmxktPT4eZmRnuPkop900XpfXtZGeBtLQ0hfetbJyYT/QBO3jwIDIzM+Hm5obExERMmjQJjo6OaNOmTannNWjQAAsWLMDdu3fh5uZWpmvFx8djxYoVTMDeQy9evMCqVavg6ekJbW1tbNq0Cfv37xctIlxRLFq0CB07doSRkRH27t2L8PBwrFix4q3nLVy4ELt375brWjo6OggNDS1vqBWSMuZwafKcMFbCiD5gf/31F7755hvcuXMHJiYmaNGiBZYuXVrqytFU8bx8+RJdu3bFxYsXkZWVBRcXFwQFBaFXr17qDk3h+vbti+joaGRkZKBGjRoYPXo0hg0bpu6wKrzCSlh8onIqYY62mlkJYxJGRERESsUkrHgcjiQiIiKV4HCkGO+OJCIiIlIDVsKIiIhIJf5bVkKxfWoqVsKIiIiI1IBJGBFVCH5+fujRo4fsddu2bfH111+rPI7o6GhIJBKkpqaW2EYikWDXrl1l7nPGjBlo1KjRO8UVHx8PiUSCmJiYd+qH6F3wsUViTMKISGn8/PwgkUggkUigq6sLZ2dnzJo1C3l5eUq/9o4dOzB79uwytS1L4kREpGicE0ZESuXl5YV169YhOzsbe/bswciRI6Gjo1PsyuM5OTnQ1dVVyHUtLCwU0g8RKY4yHjKkwYUwVsKISLn09PQglUrh4OCA4cOHo0OHDvjjjz8A/DeEGBISAjs7O9mzNx88eIC+ffvC3NwcFhYW6N69O+Lj42V95ufnY/z48TA3N4elpSUmTZqEN5c8fHM4Mjs7G5MnT4a9vT309PTg7OyMtWvXIj4+Hu3atQPw6gHtEokEfn5+AICCggLMmzcPTk5OMDAwQMOGDbFt2zbRdfbs2YPatWvDwMAA7dq1E8VZVpMnT0bt2rVhaGiIGjVqIDg4GLm5uUXa/fTTT7C3t4ehoSH69u0repYhAKxZswZ16tSBvr4+XF1dy7QSPJFKSZS0aSgmYUSkUgYGBsjJyZG9PnDgAGJjYxEVFYXIyEjk5ubC09MTJiYmOHr0KI4fPw5jY2N4eXnJzvv+++8RFhaGX375BceOHUNKSgp27txZ6nW/+uorbNq0CcuWLcONGzfw008/wdjYGPb29ti+fTsAIDY2FomJifjhhx8AAPPmzcP69euxatUqXLt2DePGjcPAgQNx+PBhAK+SxV69eqFr166IiYnBkCFDEBgYKPdnYmJigrCwMFy/fh0//PADfv75ZyxZskTU5vbt2/jtt9+we/du7Nu3DxcvXsSIESNkxyMiIjBt2jSEhITgxo0bmDt3LoKDgxEeHi53PESkIgIRkZL4+voK3bt3FwRBEAoKCoSoqChBT09PmDBhguy4jY2NkJ2dLTtnw4YNgouLi1BQUCDbl52dLRgYGAh//fWXIAiCYGtrK3z33Xey47m5uUK1atVk1xIEQfDw8BDGjh0rCIIgxMbGCgCEqKioYuM8dOiQAEB49uyZbF9WVpZgaGgonDhxQtTW399fGDBggCAIgjBlyhShbt26ouOTJ08u0tebAAg7d+4s8fjChQuFpk2byl5Pnz5d0NbWFh4+fCjbt3fvXkFLS0tITEwUBEEQatasKWzcuFHUz+zZswV3d3dBEATh7t27AgDh4sWLJV6XSFnS0tIEAEJCcqqQkVWg0C0hOVUAIKSlpan7bcqNc8KISKkiIyNhbGyM3NxcFBQU4IsvvsCMGTNkx93c3ETzwC5duoTbt2/DxMRE1E9WVhbi4uKQlpaGxMRENG/eXHasUqVKaNasWZEhyUIxMTHQ1taGh4dHmeO+ffs2Xrx4gY4dO4r25+TkoHHjxgCAGzduiOIAAHd39zJfo9CWLVuwbNkyxMXFITMzE3l5eUUev1K9enVUrVpVdJ2CggLExsbCxMQEcXFx8Pf3R0BAgKxNXl4ezMzM5I6HiFSDSRgRKVW7du2wcuVK6Orqws7ODpUqif/ZMTIyEr3OzMxE06ZNERERUaSvKlWqlCsGAwMDuc/JzMwEAPz555+i5Ad4Nc9NUU6ePAkfHx/MnDkTnp6eMDMzw+bNm/H999/LHevPP/9cJCnU1tZWWKxE74qPLRJjEkZESmVkZARnZ+cyt2/SpAm2bNkCa2vrEh/Ga2tri9OnT6NNmzYAXlV8zp8/jyZNmhTb3s3NDQUFBTh8+DA6dOhQ5HhhJS4/P1+2r27dutDT08P9+/dLrKDVqVNHdpNBoVOnTr39Tb7mxIkTcHBwwNSpU2X77t27V6Td/fv38ejRI9jZ2cmuo6WlBRcXF9jY2MDOzg537tyBj4+PXNcnIvXhxHwieq/4+PjAysoK3bt3x9GjR3H37l1ER0djzJgxePjwIQBg7NixmD9/Pnbt2oWbN29ixIgRpa7x5ejoCF9fXwwePBi7du2S9fnbb78BABwcHCCRSBAZGYl///0XmZmZMDExwYQJEzBu3DiEh4cjLi4OFy5cQGhoqGyy+7Bhw3Dr1i1MnDgRsbGx2LhxI8LCwuR6v7Vq1cL9+/exefNmxMXFYdmyZcXeZKCvrw9fX19cunQJR48exZgxY9C3b19IpVIAwMyZMzFv3jwsW7YM//zzD65cuYJ169Zh8eLFcsVDpEy8OVKMSRgRvVcMDQ1x5MgRVK9eHb169UKdOnXg7++PrKwsWWXsm2++wZdffglfX1+4u7vDxMQEPXv2LLXflStX4vPPP8eIESPg6uqKgIAAPH/+HABQtWpVzJw5E4GBgbCxscGoUaMAALNnz0ZwcDDmzZuHOnXqwMvLC3/++SecnJwAvJqntX37duzatQsNGzbEqlWrMHfuXLneb7du3TBu3DiMGjUKjRo1wokTJxAcHFyknbOzM3r16oUuXbqgU6dOaNCggWgJiiFDhmDNmjVYt24d3Nzc4OHhgbCwMFmsRPT+kQglzWQlIiIiUoD09HSYmZkh8UlqidMM3qVvWytzpKWlKbxvZeOcMCIiIlIJyf/+U3SfmorDkURERERqwEoYERERqQSXqBBjEkZEREQqkZ6erhF9qgqTMCIiIlIqXV1dSKVS1HKyV0r/UqlU9OQNTcG7I4mIiEjpsrKykJOTo5S+dXV1oa+vr5S+lYlJGBEREZEa8O5IIiIiIjVgEkZERESkBkzCiIiIiNSASRgRERGRGjAJIyIiIlIDJmFEREREasAkjIiIiEgN/h/ZUlSctNZ5PQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN (True Negatives): 885\n",
      "FP (False Positives): 631\n",
      "FN (False Negatives): 785\n",
      "TP (True Positives): 775\n"
     ]
    }
   ],
   "source": [
    "# 1. Вычисление матрицы (математическое ядро)\n",
    "# y_test - истинные значения\n",
    "# y_pred - предсказания модели\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 2. Визуализация\n",
    "# display_labels - подписи классов (0 и 1)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Low Rating (0)', 'High Rating (1)'])\n",
    "\n",
    "# Отрисовка\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "disp.plot(cmap='Blues', ax=ax, values_format='d') # values_format='d' убирает научную нотацию (1e3)\n",
    "plt.title(\"Матрица ошибок (Confusion Matrix)\")\n",
    "plt.show()\n",
    "\n",
    "# 3. Числовой вывод для анализа\n",
    "print(\"TN (True Negatives):\", cm[0][0])\n",
    "print(\"FP (False Positives):\", cm[0][1])\n",
    "print(\"FN (False Negatives):\", cm[1][0])\n",
    "print(\"TP (True Positives):\", cm[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9340f7a",
   "metadata": {},
   "source": [
    "Перейдем к деревьям решений. Вот как можно представить их себе.\n",
    "\n",
    "Изначально мы берем все признаки (столбцы, строки) и для каждого значения каждого признака делим всю таблицу на две части. Для каждой части считаем среднее значение. Например, мы разделим весь набор на две части, в одной среднее будет 5, в другой 10. Смотрим, насколько реальные значения нашего y совпадают с этими средними. Для каждой части получится свое значение. В итоге мы ищем такое разбиение, которое даст наименьшую разность.\n",
    "\n",
    "Записать это можно так:\n",
    "\n",
    "$$ R_1(j, s) = \\{X \\mid X_j < s\\} \\quad \\text{и} \\quad R_2(j, s) = \\{X \\mid X_j \\geq s\\} $$\n",
    "\n",
    "$$ \\min_{j, s} \\left[ \\sum_{i: x_i \\in R_1(j,s)} (y_i - \\hat{y}_{R_1})^2 + \\sum_{i: x_i \\in R_2(j,s)} (y_i - \\hat{y}_{R_2})^2 \\right] $$\n",
    "\n",
    "Для всех признаков и всех наблюдений в наборе данных определяются точки расщепления (значения больше и меньше этой точки). Для каждой определяется мера однородности, как правило через коэффициент Джинни. Выбирается точка с большей однородностью. Это будет узел, который разбивает данные на две группы. Применяю к каждой новой группе тот же механизм.\n",
    "\n",
    "Важные понятия:\n",
    "\n",
    "1) корневой узел – узел, с которого начинается расщепление;\n",
    "2) листовой узел  - узел, который не имеет дочерних узлов.\n",
    "\n",
    "Деревья могут применяться как к дихотамическим, так и непрерывным зависимым переменным. В этом случае вместо коэффициента Джинни или энтропии для расщепления применяется MSE.\n",
    "\n",
    "Как и в любой модели машинного обучения, стоит задача по оптимизации целевой функции. Такая целевая функция для деревьев – максимум прироста информации для каждого разделения. Математически это может быть записано, учитывая, что родительский узел, как правило, разбивается на левый и правый, следующим образом:\n",
    "\n",
    "$$ IG(D_p, f) = I(D_p) - \\frac{N_{left}}{N_p} I(D_{left}) - \\frac{N_{right}}{N_p} I(D_{right}) $$\n",
    "\n",
    "В этой формуле f - признак для выполнения разбиения, Dp - набор данных родительского узла, Dleft - левый дочерний узел, Dright - правый дочерний узел, I мера загрязненности, Np - общее количество образцов в родительском узле и Nright (Nправ) - количество образцов в соответствующих узлах.\n",
    "\n",
    "Есть три популярные меры загрязненности - коэффициент Джинни, энтропия, ошибка классификации. Как правило, используется коэффициент Джинни. \n",
    "\n",
    "Рассмотрим работу индекса Джини в задаче бинарной классификации (книга «Хорошая» / «Плохая»).\n",
    "\n",
    "Пусть в узле дерева $K$ классов, а $\\hat{p}_k$ — доля объектов класса $k$ в узле.\n",
    "\n",
    "$$\n",
    "G = \\sum_{k=1}^{K} \\hat{p}_k (1 - \\hat{p}_k)\n",
    "$$\n",
    "\n",
    "Посмотрим, какие могут быть варианты.\n",
    "\n",
    "Пускай в узел попали 10 книг, все с высоким рейтингом. Тогда\n",
    "\n",
    "$$\n",
    "\\hat{p}_1 = \\frac{10}{10} = 1.0,\\quad\n",
    "\\hat{p}_0 = \\frac{0}{10} = 0.0\n",
    "$$\n",
    "\n",
    "$$\n",
    "G = 1.0(1 - 1.0) + 0.0(1 - 0.0) = 0\n",
    "$$\n",
    "\n",
    "Вывод: \n",
    "$G = 0$ — минимальное значение индекса Джини.  \n",
    "Узел полностью однороден.\n",
    "\n",
    "Теперь предположим, что в узел попали все те же 10 книг, но из них 5 хороших и 5 плохих. Тогда  \n",
    "\n",
    "$$\n",
    "\\hat{p}_1 = 0.5,\\quad\n",
    "\\hat{p}_0 = 0.5\n",
    "$$\n",
    "\n",
    "$$\n",
    "G = 0.5(1 - 0.5) + 0.5(1 - 0.5)\n",
    "= 0.25 + 0.25\n",
    "= 0.5\n",
    "$$\n",
    "\n",
    "Вывод:  \n",
    "Для бинарной классификации $0.5$ — максимум индекса Джини.\n",
    "\n",
    "Возьмем и третий пример. Пускай дано 100 книг в узле, причем из них 20 хороших и 80 плохих. Тогда\n",
    "\n",
    "$$\n",
    "\\hat{p}_1 = 0.2,\\quad\n",
    "\\hat{p}_0 = 0.8\n",
    "$$\n",
    "\n",
    "$$\n",
    "G = 0.2(1 - 0.2) + 0.8(1 - 0.8)\n",
    "= 0.16 + 0.16\n",
    "= 0.32\n",
    "$$\n",
    "\n",
    "Вывод:\n",
    "$0.32 < 0.5$ — узел более чистый.\n",
    "\n",
    "А теперь давайте посмотрим, как происходит разбиение. \n",
    "\n",
    "Пусть в родительском узле 100 книг:\n",
    "\n",
    "- 50 хороших\n",
    "- 50 плохих\n",
    "\n",
    "$$\n",
    "G_{\\text{parent}}\n",
    "= 1 - (0.5^2 + 0.5^2)\n",
    "= 0.5\n",
    "$$\n",
    "\n",
    "Делим этот узел на две части по 50 книг. Причем получаем такое разделение:\n",
    "\n",
    "\n",
    "Left: 30 хороших, 20 плохих (50 книг)  \n",
    "Right: 20 хороших, 30 плохих (50 книг)\n",
    "\n",
    "Индекс Джини в дочерних узлах:\n",
    "\n",
    "$$\n",
    "G_{\\text{left}}\n",
    "= 1 - (0.6^2 + 0.4^2)\n",
    "= 0.48\n",
    "$$\n",
    "\n",
    "$$\n",
    "G_{\\text{right}}\n",
    "= 1 - (0.4^2 + 0.6^2)\n",
    "= 0.48\n",
    "$$\n",
    "\n",
    "Взвешенный индекс Джини:\n",
    "\n",
    "$$\n",
    "G_{\\text{split}}\n",
    "= \\frac{50}{100} \\cdot 0.48\n",
    "+ \\frac{50}{100} \\cdot 0.48\n",
    "= 0.48\n",
    "$$\n",
    "\n",
    "Падение Джини:\n",
    "\n",
    "$$\n",
    "\\text{Gini Gain}\n",
    "= 0.5 - 0.48\n",
    "= 0.02\n",
    "$$\n",
    "\n",
    "А вот другое разбиение того же узла в 100 книг. После разбиения получили:\n",
    "\n",
    "Left: 45 хороших, 5 плохих (50 книг)  \n",
    "Right: 5 хороших, 45 плохих (50 книг)\n",
    "\n",
    "Индекс Джини в дочерних узлах:\n",
    "\n",
    "$$\n",
    "G_{\\text{left}}\n",
    "= 1 - (0.9^2 + 0.1^2)\n",
    "= 0.18\n",
    "$$\n",
    "\n",
    "$$\n",
    "G_{\\text{right}}\n",
    "= 1 - (0.1^2 + 0.9^2)\n",
    "= 0.18\n",
    "$$\n",
    "\n",
    "Взвешенный индекс Джини:\n",
    "\n",
    "$$\n",
    "G_{\\text{split}}\n",
    "= \\frac{50}{100} \\cdot 0.18\n",
    "+ \\frac{50}{100} \\cdot 0.18\n",
    "= 0.18\n",
    "$$\n",
    "\n",
    "Падение Джини:\n",
    "\n",
    "$$\n",
    "\\text{Gini Gain}\n",
    "= 0.5 - 0.18\n",
    "= 0.32\n",
    "$$\n",
    "\n",
    "Сравним оба разбиение по падению индекса:\n",
    "\n",
    "- Разбиение A: $\\text{Gini Gain} = 0.02$\n",
    "- Разбиение B: $\\text{Gini Gain} = 0.32$\n",
    "\n",
    "Алгоритм выберет **разбиение B**,так как оно сильнее уменьшает неопределённость классов.\n",
    "\n",
    "Теперь про алгоритм ансамблевого обучения. \n",
    "\n",
    "Два основных типа ансамблей - бэггинг и бустинг. \n",
    "\n",
    "Бэггинг предполагает создание нескольких деревьев. Каждое дерево тренируется на наборе данных, который извлечен из базовых наборов путем отбора наблюдений и признаков.\n",
    "\n",
    "Бустинг предполагает также создание нескольких деревьев. Но деревья тренируются не параллельно, а последовательно. Причем на каждом последующем шаге учитываются результаты предыдущего. \n",
    "\n",
    "Алгоритм случайного леса:\n",
    "\n",
    "1. Извлечь случайную бутстрэп-выборку размером n (случайно выбрать n образцов из обучающего набора с возвращением).\n",
    "\n",
    "2. Вырастить дерево принятия решений из бутстрэп-выборки. В каждом узле:\n",
    "\n",
    "а) случайно выбрать d признаков без возвращения;\n",
    "б) разделить узел, используя признак, который обеспечивает наилучшее разделение согласно целевой функции.\n",
    "\n",
    "3. Повторить k раз шаги 1 и 2.\n",
    "\n",
    "4. Объединить прогнозы всех деревьев путем назначения метки класса по большинству голосов.\n",
    "\n",
    "Алгоритм бустинга:\n",
    "\n",
    "1. Произвести выборку случайного поднабора обучающих образцов d1 без возвращения из обучающего набора D для обучения слабого ученика C1.\n",
    "2. Произвести выборку второго случайного поднабора обучающих образцов d2 без возвращения из обучающего набора и добавить 50% образцов, которые ранее были неправильно классифицированы, для обучения слабого ученика C2.\n",
    "3. Найти в обучающем наборе D обучающие образцы d3, по которым C1 и C2 расходятся, для обучения третьего слабого ученика C3.\n",
    "4. Объединить слабых учеников C1, C2, C3 посредством мажоритарного голосования.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "413b1eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Tree): 0.5803\n",
      "\n",
      "Отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.76      0.64      1516\n",
      "           1       0.63      0.41      0.50      1560\n",
      "\n",
      "    accuracy                           0.58      3076\n",
      "   macro avg       0.59      0.58      0.57      3076\n",
      "weighted avg       0.59      0.58      0.57      3076\n",
      "\n",
      "\n",
      "Топ важных признаков:\n",
      "                    Importance\n",
      "num_pages             0.620599\n",
      "ratings_count         0.215587\n",
      "text_reviews_count    0.163814\n"
     ]
    }
   ],
   "source": [
    "# 1. Создание модели\n",
    "# max_depth=5: Ограничиваем дерево 5 уровнями вопросов.\n",
    "# Без этого параметра дерево построит ветку для каждой уникальной книги (Overfitting).\n",
    "tree_model = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=42)\n",
    "\n",
    "# 2. Обучение\n",
    "# Подаем X_train (можно без scaler, так интерпретируемость выше)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Предсказание\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "\n",
    "# 4. Оценка\n",
    "print(f\"Accuracy (Tree): {accuracy_score(y_test, y_pred_tree):.4f}\")\n",
    "print(\"\\nОтчет о классификации:\")\n",
    "print(classification_report(y_test, y_pred_tree))\n",
    "\n",
    "# 5. Важность признаков (Feature Importance)\n",
    "# Дерево показывает, какие вопросы оно задавало чаще всего\n",
    "import pandas as pd\n",
    "feat_importances = pd.DataFrame(tree_model.feature_importances_, index=X.columns, columns=[\"Importance\"])\n",
    "print(\"\\nТоп важных признаков:\")\n",
    "print(feat_importances.sort_values(by=\"Importance\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bde16c7",
   "metadata": {},
   "source": [
    "Получили небольшой прирост Accuracy. Теперь попробуем случайный лес, а также заодно получим коэффициенты важности признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fc117c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Random Forest): 0.5966\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.68      0.62      1516\n",
      "           1       0.62      0.52      0.57      1560\n",
      "\n",
      "    accuracy                           0.60      3076\n",
      "   macro avg       0.60      0.60      0.59      3076\n",
      "weighted avg       0.60      0.60      0.59      3076\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Инициализация модели\n",
    "# n_estimators=100: Строим \"парламент\" из 100 деревьев\n",
    "# max_depth=12: Ограничиваем глубину, чтобы деревья не зубрили шум\n",
    "# n_jobs=-1: Параллелим вычисления на все ядра процессора\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    max_depth=12, \n",
    "    max_features='sqrt',\n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 2. Обучение (Масштабирование для леса не требуется)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Предсказание\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# 4. Оценка качества\n",
    "print(f\"Accuracy (Random Forest): {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(\"\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# 5. Анализ важности признаков (Feature Importance)\n",
    "# Лес позволяет увидеть, какие признаки реально влияют на рейтинг\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feat_importances = pd.Series(rf_model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.title(\"Топ признаков, влияющих на рейтинг\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2f7bd4",
   "metadata": {},
   "source": [
    "Здесь Accuracy еще лучше. Попробуем вместе бэггинга применить бустинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46e303c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Gradient Boosting): 0.6008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.67      0.62      1516\n",
      "           1       0.62      0.54      0.58      1560\n",
      "\n",
      "    accuracy                           0.60      3076\n",
      "   macro avg       0.60      0.60      0.60      3076\n",
      "weighted avg       0.60      0.60      0.60      3076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Инициализация\n",
    "# learning_rate=0.1: шаг градиентного спуска. Чем меньше, тем точнее, но дольше.\n",
    "# n_estimators=100: количество шагов (деревьев).\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. Обучение\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Предсказание\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# 4. Оценка\n",
    "print(f\"Accuracy (Gradient Boosting): {accuracy_score(y_test, y_pred_gb):.4f}\")\n",
    "print(classification_report(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94302b5",
   "metadata": {},
   "source": [
    "Мы получили неплохой результат в 0.60, на этом здесь и остановимся."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
