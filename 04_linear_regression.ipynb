{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c634f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34917f98",
   "metadata": {},
   "source": [
    "# Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d07a61",
   "metadata": {},
   "source": [
    "Историю статистического обучения начинают с начала 19 века. Гаусс разрабатыват метод наименьших квадратов, на основе которого затем построят линейную регрессию. Эта регрессия оценивала только количественные признаки. Для оценки качественных переменных появился в 1936 метод линейного дискриминантного анализа. В 40-ых годах 20 века появляется логистическая регрессия. В 70-ых оба вида регрессии, да еще несколько, объединили в класс обобщенных линейных моделей. В это же время появляется разведочный анализ данных Тьюки.\n",
    "\n",
    "Использование линейных методов объяснялось недостаточной вычислительной мощностью. Для нелинейных методов нужна была большая мощность, которая и возникла в 80-ых. Так появились деревья регрессии и классификации, нейронные сети. В 90-ых появился метод опорных векторов. С этого момента статистичекое обучение становится самостоятельным направлением в статистике. \n",
    "\n",
    "Метод линейной регрессии остается основным в статистическом обучении, потому что именно из него порождено все развитие статистического обучения.\n",
    "Суть же линейной регрессии можно свести к следующей формуле:\n",
    "\n",
    "$$ Y = f(X) + \\epsilon $$\n",
    "\n",
    "Задумаемся над этоф формулой. У нас есть число, которое мы хотим узнать (y), есть число, которое мы знаем (x). Если у нас есть 8, то 3 до 8 можно \"поднять\" умножением на 2. Тогда наша f будет таким вот 2x, причем еще останется ошибка 8 - 2x3 = 8 - 6 = 2. По существу этим и занимается статистическое обучение. У нас есть два известных набора чисел, надо найти функцию, которая максимально \"подгонит\" один набор к другому. Если у нас это получится, то мы сможем при налии одного набора получить другой, даже если этот \"один\" будет совсем новым.\n",
    "\n",
    "Это нам показывает и ограниченность подобного обучения. Мы не ищем причин, не задумываемся о развитии процессов. Нам важно подогнать один набор чисел к другому. Поэтому нам важно, чтобы наборы эти были \"очищенными\", не было выбросов, они подчинялись какому-то распределению известному. В той степени, в какой любой процесс можт быть описан количественно, в той степени подобный подход может сработать. Однако по той же причине он не будет работать, если нам нужно не только количественное, но и качественное понимание. \n",
    "\n",
    "Статистическое обучение занимается двумя вопросами: 1) предсказанием, 2) статистическим выводом. Когда наша цель получить предсказание, то нас может даже не волновать сама функция f, нам главное, чтобы получаемые результаты были близки к реальным, а как это достигается – особого значения не имеет. Другое дело, когда нам нужен статистический вывод. Здесь мы уже интересуемся самой функцией, потому что хотим узнать связь y и функции.\n",
    "\n",
    "Как искать f? Есть параметрический и непараметрический подходы. \n",
    "\n",
    "При параметрическом подходе мы делаем предположение о том, как может выглядеть наша функция. Типичный пример – линейная функция:\n",
    "\n",
    "$$ f(X) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p + \\epsilon$$\n",
    "\n",
    "Иксы здесь – это те сведения, которые у нас есть, а бета – это коэффициенты. Нам надо так подобрать бета, чтобы наши иксы давали на выходе результат, совпадающий с y. Способов подбора таких значений много, самый популярный – метод наименьших квадратов.\n",
    "\n",
    "Графически представить линейную регрессию можно так\n",
    "\n",
    "<img src=\"./images/linreg5.png\" alt=\"Линейная регрессия график\" width=\"500\">\n",
    "\n",
    "В линейной регрессии мы имеем дело вот с чем. Вернемся к этому уравнению:\n",
    "\n",
    "$$ f(X) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p + \\epsilon$$\n",
    "\n",
    "мы можем перенести налево от знака уравнения все элементы, кроем значка эпсилона. \n",
    "\n",
    "$$ f(X) - \\beta_0 - \\beta_1 X_1 - \\beta_2 X_2 - \\dots - \\beta_p X_p = \\epsilon$$\n",
    "\n",
    "Смысл этой записи такой: из известного значения y, то есть f(X), мы отнимаем наше предполагаемое значение, результат даст ошибку. Если сделать так для каждого известного y, то мы получим сумму квадратов остатков или RSS. Вот как то же самое можно записать еще иначе:\n",
    "\n",
    "$$RSS(\\beta_0, \\beta_1) = \\sum_{i=1}^{n} (y_i - (\\beta_0 + \\beta_1 x_i))^2 \\to \\min$$\n",
    "\n",
    "Нам надо найти, в каких точках эта функция, то есть сумма квадратов остатков, достигает минимума, а значит нуля. Ищут это с помощью производных. Производную всей функции мы берем сначала по $beta_0$, а затем по $beta_1$. \n",
    "\n",
    "Начнем с $beta_0$. У нас $\\sum_{i=1}^{n} (y_i - (\\beta_0 + \\beta_1 x_i))^2$ сложная функция: внутри линейная, а снаружи квадрат.\n",
    "\n",
    "По правилу дифференцирования сложной функции:$$[f(g(x))]' = \\underbrace{f'(g(x))}_{\\text{Производная внешней}} \\cdot \\underbrace{g'(x)}_{\\text{Производная внутренней}}$$\n",
    "\n",
    "Начнем с производной внешней функции, то есть квадрата. \n",
    "\n",
    "Производная от $u^2$ равна $2u$. У нас $u$ – это $(y_i - (\\beta_0 + \\beta_1 x_i))^2$. Тогда имеем:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial u} (u^2) = 2 \\cdot (y_i - \\beta_0 - \\beta_1 x_i)$$\n",
    "\n",
    "Теперь берем производную внутренней функции по $\\beta_0$. \n",
    "\n",
    "Смотрим на слагаемые внутри скобки $(y_i - \\beta_0 - \\beta_1 x_i)$:\n",
    "\n",
    "$y_i$ — константа (число из датасета). Производная константы = $0$;\n",
    "\n",
    "$-\\beta_1 x_i$ — константа (относительно $\\beta_0$ это число). Производная = $0$;\n",
    "\n",
    "$-\\beta_0$ — это наша переменная, ведь по ней мы и берем производную. Но эта производная равна $-1$. \n",
    "\n",
    "Итого, производная внутренней функции: $-1$.\n",
    "\n",
    "Теперь перемножаем полученные результаты: $$\\underbrace{2(y_i - \\beta_0 - \\beta_1 x_i)}_{\\text{Внешняя}} \\cdot \\underbrace{(-1)}_{\\text{Внутренняя}}$$Выносим константы $-1$ и $2$ за знак суммы, так как они общие для всех $i$:$$-2 \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1 x_i)$$\n",
    "\n",
    "$$\\frac{\\partial RSS}{\\partial \\beta_0} = \\sum_{i=1}^{n} 2(y_i - \\beta_0 - \\beta_1 x_i) \\cdot (-1) = -2 \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1 x_i)$$\n",
    "\n",
    "Раз мы получили производную, то теперь приравняем ее к нулю:\n",
    "\n",
    "$$-2 \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1 x_i) = 0 \\implies \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1 x_i) = 0$$\n",
    "\n",
    "Раскрываем сумму в уравнении:$$\\sum y_i - \\sum \\beta_0 - \\sum \\beta_1 x_i = 0$$Учитывая, что $\\sum_{i=1}^n \\text{const} = n \\cdot \\text{const}$, получаем:$$\\sum y_i - n\\beta_0 - \\beta_1 \\sum x_i = 0$$Выражаем $\\beta_0$:$$n\\beta_0 = \\sum y_i - \\beta_1 \\sum x_i$$Делим обе части на $n$:$$\\beta_0 = \\frac{\\sum y_i}{n} - \\beta_1 \\frac{\\sum x_i}{n}$$Так как среднее $\\bar{y} = \\frac{\\sum y_i}{n}$ и $\\bar{x} = \\frac{\\sum x_i}{n}$, получаем искомую формулу:$$\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}$$\n",
    "\n",
    "Теперь переходим к $beta_1$.\n",
    "\n",
    "Мы снова дифференцируем квадрат скобки $u^2$. Производная внешней функции равна $2u$: $$\\frac{\\partial}{\\partial u}(u^2) = 2 \\cdot (y_i - \\beta_0 - \\beta_1 x_i)$$\n",
    "\n",
    "Теперь нам нужно найти производную содержимого скобки по $\\beta_1$:$$u = y_i - \\beta_0 - \\beta_1 x_i$$ \n",
    "\n",
    "Дифференцируем каждое слагаемое отдельно:\n",
    "\n",
    "$y_i$ – константа. Производная = $0$;\n",
    "\n",
    "$-\\beta_0$ – константа (так как мы ищем $\\partial / \\partial \\beta_1$). Производная = $0$;\n",
    "\n",
    "$-\\beta_1 x_i$ – это линейный член вида $k \\cdot z$, где переменная $z = \\beta_1$, а коэффициент $k = -x_i$. Производная от $ax$ равна $a$.\n",
    "\n",
    "Следовательно, производная от $(-\\beta_1) \\cdot x_i$ равна $-x_i$. Итого, производная внутренней функции: $-x_i$.\n",
    "\n",
    "По цепному правилу умножаем внешнюю производную на внутреннюю:$$\\underbrace{2(y_i - \\beta_0 - \\beta_1 x_i)}_{\\text{Внешняя}} \\cdot \\underbrace{(-x_i)}_{\\text{Внутренняя}}$$\n",
    "\n",
    "Выносим числовые множители. Множитель $2$ и знак минус от $-x_i$ объединяются в $-2$. Переменная $x_i$ остается внутри суммы, так как она зависит от индекса $i$ (для каждой точки свой $x$, его выносить нельзя). Получаем итоговую формулу:$$-2 \\sum_{i=1}^{n} x_i (y_i - \\beta_0 - \\beta_1 x_i)$$\n",
    "\n",
    "Теперь имеем: \n",
    "\n",
    "$$\\frac{\\partial RSS}{\\partial \\beta_1} = \\sum_{i=1}^{n} 2(y_i - \\beta_0 - \\beta_1 x_i) \\cdot (-x_i) = -2 \\sum_{i=1}^{n} x_i (y_i - \\beta_0 - \\beta_1 x_i)$$Приравниваем к нулю:$$\\sum_{i=1}^{n} x_i (y_i - \\beta_0 - \\beta_1 x_i) = 0$$\n",
    "\n",
    "Берем уравнение и подставляем в него только что найденное выражение для $\\beta_0$:$$\\sum x_i (y_i - (\\bar{y} - \\beta_1 \\bar{x}) - \\beta_1 x_i) = 0$$Группируем слагаемые внутри скобки:$$\\sum x_i ((y_i - \\bar{y}) - \\beta_1 (x_i - \\bar{x})) = 0$$Раскрываем скобки:$$\\sum x_i (y_i - \\bar{y}) - \\beta_1 \\sum x_i (x_i - \\bar{x}) = 0$$Переносим $\\beta_1$ в правую часть:$$\\beta_1 \\sum x_i (x_i - \\bar{x}) = \\sum x_i (y_i - \\bar{y})$$Отсюда получаем промежуточную формулу:$$\\hat{\\beta}_1 = \\frac{\\sum x_i (y_i - \\bar{y})}{\\sum x_i (x_i - \\bar{x})}$$\n",
    "\n",
    "Теперь займемся отдельно числителем и знаменателем. В обоих случаях используем свойство суммы отклонений от среднего:$$\\sum_{i=1}^n (x_i - \\bar{x}) = 0 \\quad \\text{и} \\quad \\sum_{i=1}^n (y_i - \\bar{y}) = 0$$\n",
    "\n",
    "Начнем с числителя. Рассмотрим выражение:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} x_i (y_i - \\bar{y}).\n",
    "$$\n",
    "\n",
    "Представим $x_i$ в виде:\n",
    "\n",
    "$$\n",
    "x_i = (x_i - \\bar{x}) + \\bar{x}.\n",
    "$$\n",
    "\n",
    "Подставим в сумму:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} \\big[(x_i - \\bar{x}) + \\bar{x}\\big] (y_i - \\bar{y}).\n",
    "$$\n",
    "\n",
    "Раскроем скобки:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y}) \\;+\\; \\bar{x} \\sum_{i=1}^{n} (y_i - \\bar{y}).\n",
    "$$\n",
    "\n",
    "Так как\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} (y_i - \\bar{y}) = 0,\n",
    "$$\n",
    "\n",
    "второе слагаемое равно нулю. Следовательно:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} x_i (y_i - \\bar{y}) = \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y}).\n",
    "$$\n",
    "\n",
    "Аналогично поступим с знаменателем. Рассмотрим:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} x_i (x_i - \\bar{x}).\n",
    "$$\n",
    "\n",
    "Подставим разложение:\n",
    "\n",
    "$$\n",
    "x_i = (x_i - \\bar{x}) + \\bar{x}.\n",
    "$$\n",
    "\n",
    "Получаем:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} \\big[(x_i - \\bar{x}) + \\bar{x}\\big] (x_i - \\bar{x}).\n",
    "$$\n",
    "\n",
    "Раскрываем скобки:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} (x_i - \\bar{x})^2 \\;+\\; \\bar{x} \\sum_{i=1}^{n} (x_i - \\bar{x}).\n",
    "$$\n",
    "\n",
    "Так как\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} (x_i - \\bar{x}) = 0,\n",
    "$$\n",
    "\n",
    "второе слагаемое исчезает, и остаётся:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} x_i (x_i - \\bar{x}) = \\sum_{i=1}^{n} (x_i - \\bar{x})^2.\n",
    "$$\n",
    "\n",
    "Итоговые формулы для простой линейной регрессии:\n",
    "\n",
    "Коэффициент наклона:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}\n",
    "$$\n",
    "\n",
    "Смещение (свободный член):\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}\n",
    "$$\n",
    "\n",
    "Итак, это был параметрический подход, который привел нас к методу наименьших квадратов. Непараметрические методы не делают предположений о функции, они просто подгоняют данные под результат. Из-за этого нужно больше данных, чем при использовании методов параметрических. \n",
    "\n",
    "Методы могут быть не только параметрическими и непараметрическими, но и с учителем и без учителя. Разница в том, что с учителем у нас есть результат, который мы должны предсказать. Без учителя у нас такого результата нет, у нас есть признаки, но не следствие из них. Методом без учителя является, например, кластеризация. \n",
    "\n",
    "Идеального метода обучения не бывает. В учебниках даже пишут, что на очень похожих данных может не получиться использовать одинаковые инструменты. \n",
    "\n",
    "Результаты работы нашей модели надо оценить. В регрессионных задачах чаще всего используется среднеквадратичная ошибка (mean \n",
    "squared error – MSE). \n",
    "\n",
    "Здесь мы вплотную подошли к машинному обучению. Линейная регрессия становится задачей машинного обучения, когда данных становится слишком много, чтобы их можно было обработь в ручную.\n",
    "\n",
    "Методы машинного обучения тоже можно разделить на:\n",
    "\n",
    "1) обучение с учителем;\n",
    "2) обучение без учителя;\n",
    "3) обучение с подкреплением.\n",
    "\n",
    "Также методы машинного обучения можно разделить на:\n",
    "1) решение задачи регрессии (для непрерывных числовых данных);\n",
    "2) решение задачи классификации (для категориальных данных).\n",
    "\n",
    "Линейная регрессия относится к методом обучения с учителем. Это предполагает, что есть данные, которые используются для обучения. Эти данные разделены на:\n",
    "\n",
    "1) независимые переменные (или просто переменные);\n",
    "2) зависимые переменные.\n",
    "\n",
    "Обратимся сразу к примеру на основе данных о книгах:\n",
    "\n",
    "**num_pages**, **language_code** - это переменные,\n",
    "**average_rating** - зависимая переменная.\n",
    "\n",
    "Обучение с учителем означает, что надо взять переменные и на их основе с помощью математических операций найти связи с зависимой переменной. Характер этой связи между переменными и зависимой переменнойм: конкретные значения переменных определяют конкретную зависимую переменную. \n",
    "\n",
    "Визуализировать это можно еще следующим образом. Представим таблицу. В таблице по горизонтали - строки, по вертикали - столбцы. Одна строка - это одно наблюдение (в данном случае - одна книга). Столбцы, относящиеся к этой строке, - это признаки данного конкретного наблюдения (количество страниц, количество обзоров и т.п.). Среди столбцов выделяем зависимую переменную - средняя оценка. Это то, что хочется научиться предсказывать. Остальные столбцы - это переменные. Цель - на основании оставшихся столбцов (переменных) определить зависимую переменную.\n",
    "\n",
    "Для применения методов машинного обучения требуется соблюдение следующих условий: \n",
    "* зависимая переменная - непрерывная величина, переменные - могут быть непрерывной или категориальной (как правило, дихотамической) переменной;\n",
    "* оценка одной книги не зависит от оценки другой. Определяется это исследователем;\n",
    "* линейность отношений. Проверяется по графику. Например, в случае, если дан один независимый признак и один зависимый признак, график строится так: по **x** расположены значения признака, по **y** расположены значения зависимого признака;\n",
    "* непрерывные переменные должны быть нормально распределены и не должны иметь выбросов. Из статистического анализа во второй главе известно, что данные не распределены нормально;\n",
    "* гомоскедастичность, то есть постоянство ошибок предсказания модели. Это проверяется уже после построения модели на графике остатков;\n",
    "* нормальность распределения ошибок. Это также проверяется уже после построения модели, можно использовать гистограмму по остаткам. Кроме того, среднее ошибок должно быть равно нулю;\n",
    "* если используется два и более признака, то необходима проверка на мультиколлинеарность. И это проверяется после построения модели, но с помощью специальных тестов.\n",
    "* масштабирование данных. Это не является собственно условием применения линейной регрессии. Однако масштабирование требуется практически для всех методов машинного обучения, особенно в случае, если предполагается рассмотрение влияния на зависимую переменную не отдельных переменных, а их взаимосвязей. Если одна переменная выражена в миллионах, а другая в сотнях, то первая будет иметь больший вес уже только в силу этого. \n",
    "\n",
    "Смысл указанных условий в том, что при несоблюдении их нельзя полагаться на результаты линейной регрессии.\n",
    "\n",
    "При применении методов машинного обучения надо помнить следующую рекомендацию: всегда надо искать самый простой способ решения задачи. Если линейная регрессия будет хорошо справляться, то использовать более сложные способы не надо. Если же эти сложные способы дадут незначительное улучшение, то также не надо их использовать, если это ведет к излишней трате вычислительного времени. Поэтому более сложные методы можно использовать, если:\n",
    "\n",
    "1) регрессия к нашей задаче не подходит;\n",
    "2) другой метод не только лучше себя показывает, но и находится на том же уровне эффективности (или выше).\n",
    "\n",
    "Дополнительно стоит отметить следующее. Даже полное соответствие данных указанным выше условиям и применение самого продвинутого метода обучения с самым лучшим набором параметров не означает, что удастся получить модель, которая будет хорошо работать. В некоторых публикациях встречается, и даже доказывается, утверждение, что главное значение имеет не столько применяемый метод машинного обучения, сколько качество данных. \n",
    "\n",
    "Линейная регрессия может быть применена различными способами и с помощью разлинчых библиотек. Все эти способы условно можно разделить на три подхода:\n",
    "\n",
    "1) визуальный;\n",
    "2) статистический;\n",
    "3) собственно машинное обучение.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd016e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10253 entries, 0 to 10252\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   title               10253 non-null  object \n",
      " 1   authors             10253 non-null  object \n",
      " 2   average_rating      10253 non-null  float64\n",
      " 3   language_code       10253 non-null  object \n",
      " 4   num_pages           10253 non-null  int64  \n",
      " 5   ratings_count       10253 non-null  int64  \n",
      " 6   text_reviews_count  10253 non-null  int64  \n",
      " 7   editions_count      10253 non-null  int64  \n",
      " 8   year                10253 non-null  int64  \n",
      " 9   quarter             10253 non-null  int64  \n",
      "dtypes: float64(1), int64(6), object(3)\n",
      "memory usage: 801.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>language_code</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>editions_count</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twilight (Twilight  #1)</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>3.59</td>\n",
       "      <td>eng</td>\n",
       "      <td>501</td>\n",
       "      <td>4597666</td>\n",
       "      <td>94265</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Hobbit  or There and Back Again</td>\n",
       "      <td>J.R.R. Tolkien</td>\n",
       "      <td>4.27</td>\n",
       "      <td>eng</td>\n",
       "      <td>366</td>\n",
       "      <td>2530894</td>\n",
       "      <td>32871</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Catcher in the Rye</td>\n",
       "      <td>J.D. Salinger</td>\n",
       "      <td>3.80</td>\n",
       "      <td>eng</td>\n",
       "      <td>277</td>\n",
       "      <td>2457092</td>\n",
       "      <td>43499</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title          authors  average_rating  \\\n",
       "0              Twilight (Twilight  #1)  Stephenie Meyer            3.59   \n",
       "1  The Hobbit  or There and Back Again   J.R.R. Tolkien            4.27   \n",
       "2               The Catcher in the Rye    J.D. Salinger            3.80   \n",
       "\n",
       "  language_code  num_pages  ratings_count  text_reviews_count  editions_count  \\\n",
       "0           eng        501        4597666               94265               1   \n",
       "1           eng        366        2530894               32871               1   \n",
       "2           eng        277        2457092               43499               1   \n",
       "\n",
       "   year  quarter  \n",
       "0  2006        3  \n",
       "1  2002        3  \n",
       "2  2001        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = pd.read_csv('gd_clean_data.csv', on_bad_lines='skip')\n",
    "db.info()\n",
    "db.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b921acf",
   "metadata": {},
   "source": [
    "Зависимая переменная - **average_rating**. Независимые переменные - это те признаки, на которых будет обучаться модель, чтобы получить зависимую переменную. \n",
    "\n",
    "# Визуальный подход\n",
    "\n",
    "Линейная регрессия может искать взаимосвязи между одной переменной и зависимой переменной. Или возможно искать взаимосвязь между множеством переменных (и их взаимосвязью) и зависимой переменной. Визуальный подход применяется, как правило, для случая, когда надо найти взаимосвязь между одной переменной и зависимой переменной.\n",
    "\n",
    "Важно помнить, что визуальный подход особенно хорошо работает, когда не так много данных. Как будет видно ниже, в случае, если есть более 10 тыс. наблюдений график может быть сложно прочитать.\n",
    "\n",
    "Визуальный подход применяется для того, чтобы определить, что в данных есть линейные отношения. Другими словами, это своеобразное черновое построение линейной регрессии.\n",
    "\n",
    "Визуальный подход позволяет также понять, что означает \"взаимосвязь между переменными\". При движении вдоль оси **x** значение **y** также изменяется. Если значение **y** увеличивается с увеличением по оси **x** (или уменьшается при уменьшении **x**), то речь идет о положительной (отрицательной) связи. В результате такого движения может получиться прямая линия, которая либо не имеет наклона к оси **x**, либо такой наклон имеет. Чем больше такой наклон, тем сильнее связь между признаком и целевым признаком.\n",
    "\n",
    "Но вот что получится, если строить график \"в лоб\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7feb8b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='num_pages', ylabel='average_rating'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme(color_codes=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4)) \n",
    "sns.regplot(x='num_pages', y='average_rating', data=db, scatter_kws={'s':80, 'alpha': 0.3}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ebca1c",
   "metadata": {},
   "source": [
    "Графики удобны для визуальной оценки, но к делу они особо не относятся. Поэтому перейдем к статистике. Будем использовать библиотеку statsmodels. Данная библиотека дает широкий вывод оценок модели, что позволяет проверить допущения линейной регрессии. Также будет возможность удалить выбросы.\n",
    "\n",
    "Условия применения линейной регрессии описаны выше. Часть таких условий проверяется до проведения обучения, а часть - после. Мы уже знаем, что наши данные не подчинены нормальному распределению. Поэтому применение линейной модели здесь вообще под вопросом. Однако менять из-за этого данные мы не будем. Ведь нам главное показать, как работает линейная регрессия. И с этой задачей можно справиться и на данных, которые не подходят под нормальное распределение.\n",
    "\n",
    "Поэтому сразу запустим линейную регрессию без дополнительных проверок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "866b3841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSE (Residual Standard Error): 0.2948698686972322\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         average_rating   R-squared:                       0.031\n",
      "Model:                            OLS   Adj. R-squared:                  0.031\n",
      "Method:                 Least Squares   F-statistic:                     110.8\n",
      "Date:                Wed, 24 Dec 2025   Prob (F-statistic):           1.42e-70\n",
      "Time:                        12:22:23   Log-Likelihood:                -2025.2\n",
      "No. Observations:               10253   AIC:                             4058.\n",
      "Df Residuals:                   10249   BIC:                             4087.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept              3.8665      0.005    757.022      0.000       3.856       3.877\n",
      "num_pages              0.0002   1.23e-05     17.707      0.000       0.000       0.000\n",
      "ratings_count       1.142e-07   4.99e-08      2.288      0.022    1.63e-08    2.12e-07\n",
      "text_reviews_count -1.099e-06   2.19e-06     -0.503      0.615   -5.39e-06    3.19e-06\n",
      "==============================================================================\n",
      "Omnibus:                     1758.137   Durbin-Watson:                   2.004\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             8429.842\n",
      "Skew:                          -0.755   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.178   Cond. No.                     2.08e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.08e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "formula = 'average_rating ~ num_pages + ratings_count + text_reviews_count'\n",
    "model = smf.ols(formula, data=db).fit()\n",
    "rse = model.mse_resid ** 0.5\n",
    "print(f\"RSE (Residual Standard Error): {rse}\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d46b0c3",
   "metadata": {},
   "source": [
    "Чисел в результатах модели много, об их значимости это ничего не говорит. Итак, мы искали линейную зависимость между средней оценкой и количеством страниц в книге, количеством оценок, количеством обзоров. Вывод выше можно разбить на три части по вертикали. Начнем с верхней части. Слевая там – служебная информация, которая нас не интересет. Справа - общие результаты работы нашей модели.\n",
    "\n",
    "R-squared – это коэффициент детерминации. Получают его через деление суммы квадратов ошибок на сумму отклонения от среднего значения. Смысл этого коэффициента вот в чем. Можно же предсказать зависимую переменную просто средним значением. Но мы так не делаем, мы ищем линейную модель. Когда мы такую модель нашли, то смотрим, а насколько она лушче простого предсказания средним.\n",
    "\n",
    "Пусть:\n",
    "\n",
    "- $y_i$ — наблюдаемые значения целевой переменной  \n",
    "- $\\hat{y}_i$ — предсказанные моделью значения  \n",
    "- $\\bar{y}$ — среднее значение $y$\n",
    "\n",
    "**Сумма квадратов ошибок (RSS)**\n",
    "\n",
    "$$\n",
    "RSS = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "**Сумма квадратов отклонений от среднего (TSS)**\n",
    "\n",
    "$$\n",
    "TSS = \\sum_{i=1}^{n} (y_i - \\bar{y})^2\n",
    "$$\n",
    "\n",
    "**Коэффициент детерминации**\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{RSS}{TSS} = \\frac{TSS - RSS}{TSS}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Интерпретация\n",
    "\n",
    "- $R^2 = 1$ → модель идеально объясняет все данные  \n",
    "- $R^2 = 0$ → модель не лучше простого среднего $\\bar{y}$  \n",
    "- $0 < R^2 < 1$ → часть вариации объясняется моделью, часть — случайная  \n",
    "- $R^2 < 0$ → модель хуже, чем простое среднее\n",
    "\n",
    "У нас R-squared равно 0.031, то есть модель объясняет чуть лучше, чем простое предсказание средним.\n",
    "\n",
    "F-statistic проверяет гипотезу, что все коэффициенты равны нулю. Значение 110.8 — очень высокое. Если значение близко к единице, то все коэффициенты, то есть беты, кроме беты ноль, равны нулю. Это значит отсутствие связи между признаками и y. Если же значение больше единицы, то это означает, что такая связь есть, какое-то значение бета не является единицей.\n",
    "\n",
    "$$\n",
    "F = \\frac{\\text{explained variance per predictor}}{\\text{unexplained variance per residual}}\n",
    "= \\frac{(TSS - RSS)/k}{RSS/(n-k-1)}\n",
    "$$\n",
    "\n",
    "где:  \n",
    "\n",
    "- $TSS = \\sum_{i=1}^{n} (y_i - \\bar{y})^2$ — общая сумма квадратов  \n",
    "- $RSS = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$ — сумма квадратов остатков  \n",
    "- $k$ — число предикторов  \n",
    "- $n$ — число наблюдений  \n",
    "\n",
    "Опять-таки, мы можем принять, что наша модель объясняет зависимую переменную лучше простого среднего, но лишь незначительно.\n",
    "\n",
    "Теперь посмотрим среднюю часть нашей вертикали. Здесь показаня коэффициенты для каждого члена регреессии, то есть это те самые беты. Например, каждая дополнительная страница книги прибавляет 0.0002 к оценке книги.\n",
    "\n",
    "Нижняя часть вертикали показывает диагностика остатков. Именно по остаткам проверяется допустимость полученной модели. Результаты в этой части показывают то, что нам было известно заранее, – наши данные не годятся для простой линейной модели. Попробуем подойти к этой задаче через методы машинного обучения.\n",
    "\n",
    "Чтобы применить машинное обучение, надо ответить на несколько вопросов.\n",
    "\n",
    "1) Какую модель выбрать? В этой главе мы используем линейную регрессию (возможно также применение робастной линейной регрессии, полиномиальной, а также применение регуляризации).\n",
    "\n",
    "2) Требуется ли дополнительная подготовка данных для выбранной модели? Например, можно добавить дополнительные признаки в ручном режиме или автоматически. Необходимо также масштабировать данные.\n",
    "\n",
    "3) Какие параметры модели надо настраивать и как? Можно использовать решетчатый поиск с кросс-валидацией.\n",
    "\n",
    "4) Что будет оценкой качества модели? MSE и R2.\n",
    "\n",
    "5) Как можно получить предсказания по новым данным?\n",
    "\n",
    "Порядок действий такой: \n",
    "\n",
    "1) задаем модель линейной регрессии; \n",
    "\n",
    "2) разделяем данные на тренировочный и тестовый наборы. Разделить данные можно в следующих пропорциях 80:20, 60:40 или 70:30; \n",
    "\n",
    "3) подготавливаем данные (возможно с применением метода Pipeline); \n",
    "\n",
    "4) тренируем модель с настройкой параметров и оценкой; \n",
    "\n",
    "5) выбираем лучшую модель; \n",
    "\n",
    "6) проводим проверку на тестовом наборе; \n",
    "\n",
    "7) применяем для новых данных.\n",
    "\n",
    "Важно помнить следующие два обстоятельства: \n",
    "\n",
    "1) всегда надо стремиться найти самую простую и эффективную модель. Поэтому начинать стоит с базовой. \n",
    "\n",
    "2) при подготовке данных для машинного обучения, можно добавлять признаки, очищать их, модифицировать до разделения на тренировочный и тестовый набор или после. До разделения можно применять только нематематические методы, которым не требуются расчеты на всем датафрейме. Все математические методы, которые требуют расчетов, надо применять только после разделения на тренировочный и тестовый наборы, причем только на тренировочном (с последующим применением результатов и к тестовому).\n",
    "\n",
    "Важно помнить, что надо удалить выбросы и масштабировать данные. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9755d003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>editions_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.59</td>\n",
       "      <td>501</td>\n",
       "      <td>4597666</td>\n",
       "      <td>94265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.27</td>\n",
       "      <td>366</td>\n",
       "      <td>2530894</td>\n",
       "      <td>32871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.80</td>\n",
       "      <td>277</td>\n",
       "      <td>2457092</td>\n",
       "      <td>43499</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_rating  num_pages  ratings_count  text_reviews_count  \\\n",
       "0            3.59        501        4597666               94265   \n",
       "1            4.27        366        2530894               32871   \n",
       "2            3.80        277        2457092               43499   \n",
       "\n",
       "   editions_count  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выбираем только нужные столбцы\n",
    "db = db[['average_rating', 'num_pages', 'ratings_count', 'text_reviews_count', 'editions_count']]\n",
    "db.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d871d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Linear Regression (numeric only) ===\n",
      "R2 (test): 0.0304\n",
      "RMSE (test): 0.3068\n",
      "\n",
      "Коэффициенты модели:\n",
      "              feature   coefficient\n",
      "0           num_pages  2.144249e-04\n",
      "1       ratings_count  2.057372e-07\n",
      "2  text_reviews_count -1.564282e-06\n",
      "3      editions_count -2.088688e-02\n",
      "\n",
      "Intercept: 3.8892\n",
      "RSE: 0.2919\n"
     ]
    }
   ],
   "source": [
    "X = db.drop('average_rating', axis=1)\n",
    "y = db['average_rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"=== Linear Regression (numeric only) ===\")\n",
    "print(f\"R2 (test): {r2:.4f}\")\n",
    "print(f\"RMSE (test): {rmse:.4f}\")\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'coefficient': model.coef_\n",
    "}).sort_values(by='coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nКоэффициенты модели:\")\n",
    "print(coef_df)\n",
    "\n",
    "print(f\"\\nIntercept: {model.intercept_:.4f}\")\n",
    "\n",
    "n = X_train.shape[0]\n",
    "k = X_train.shape[1]\n",
    "\n",
    "rss = np.sum((y_train - model.predict(X_train)) ** 2)\n",
    "rse = np.sqrt(rss / (n - k - 1))\n",
    "\n",
    "print(f\"RSE: {rse:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f776aa",
   "metadata": {},
   "source": [
    "Мы видим, что RSE осталось в пределах 0.29. Само по себе изменение конкретного инструмента, которым мы применяем линейную регрессию, еще не могло повлиять на результаты. Теперь попробуем чуть изменить сам инструмент. Суть изменения в том, чтобы включить в наше уравнение регрессии член, который будет относительно независим к переменным. Это называют регуляризацией.\n",
    "\n",
    "Вспомним обычную линейную регрессию:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_k x_k + \\varepsilon\n",
    "$$\n",
    "\n",
    "Применение метода наименьших квадратов вело к минимизации разницы между известным значением и предсказанным значением зависимой переменной:\n",
    "\n",
    "$$\n",
    "\\min_{\\beta} \\sum_{i=1}^{n} (y_i - \\hat y_i)^2\n",
    "$$\n",
    "\n",
    "И вот метод регуляризации означает изменение это формулы – добавляется \"штраф\":\n",
    "\n",
    "$$\n",
    "\\min_{\\beta} \\left[\n",
    "\\sum_{i=1}^{n} (y_i - \\hat y_i)^2\n",
    "\\;+\\;\n",
    "\\lambda \\cdot \\text{Penalty}(\\beta)\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "- $\\lambda \\ge 0$ — параметр регуляризации  \n",
    "- чем больше $\\lambda$, тем сильнее сжатие коэффициентов  \n",
    "\n",
    "Штраф этот может иметь разную формую. Вот Ridge-регрессия (L2-регуляризация):\n",
    "\n",
    "$$\n",
    "\\min_{\\beta}\n",
    "\\left[\n",
    "\\sum_{i=1}^{n} (y_i - \\hat y_i)^2\n",
    "\\;+\\;\n",
    "\\lambda \\sum_{j=1}^{k} \\beta_j^2\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "А вот Lasso-регрессия (L1-регуляризация):\n",
    "\n",
    "$$\n",
    "\\min_{\\beta}\n",
    "\\left[\n",
    "\\sum_{i=1}^{n} (y_i - \\hat y_i)^2\n",
    "\\;+\\;\n",
    "\\lambda \\sum_{j=1}^{k} |\\beta_j|\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c5338d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model   R2_test  RMSE_test  RSE_train\n",
      "0    OLS  0.030392   0.306831   0.291910\n",
      "1  Ridge  0.030617   0.306795   0.291911\n",
      "2  Lasso  0.035715   0.305987   0.292346\n",
      "\n",
      "Лучшие alpha:\n",
      "Ridge alpha: 100\n",
      "Lasso alpha: 0.01\n",
      "\n",
      "Коэффициенты:\n",
      "              feature       OLS     Ridge     Lasso\n",
      "0           num_pages  0.048893  0.048297  0.038875\n",
      "1       ratings_count  0.021328  0.020344  0.006348\n",
      "2  text_reviews_count -0.003825 -0.002985  0.000000\n",
      "3      editions_count -0.007929 -0.007724 -0.000000\n",
      "\n",
      "Занулённые коэффициенты Lasso:\n",
      "- text_reviews_count\n",
      "- editions_count\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 0. ДАННЫЕ\n",
    "# =========================\n",
    "\n",
    "db = db[['average_rating',\n",
    "         'num_pages',\n",
    "         'ratings_count',\n",
    "         'text_reviews_count',\n",
    "         'editions_count']].dropna()\n",
    "\n",
    "X = db.drop('average_rating', axis=1)\n",
    "y = db['average_rating']\n",
    "\n",
    "# =========================\n",
    "# 1. TRAIN / TEST\n",
    "# =========================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 2. SCALE (обязательно для регуляризации)\n",
    "# =========================\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# =========================\n",
    "# 3. OLS (базовая модель)\n",
    "# =========================\n",
    "\n",
    "ols = LinearRegression()\n",
    "ols.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_ols = ols.predict(X_test_scaled)\n",
    "\n",
    "ols_rmse = np.sqrt(mean_squared_error(y_test, y_pred_ols))\n",
    "ols_r2 = r2_score(y_test, y_pred_ols)\n",
    "\n",
    "# RSE (OLS)\n",
    "n = X_train_scaled.shape[0]\n",
    "k = X_train_scaled.shape[1]\n",
    "rss_ols = np.sum((y_train - ols.predict(X_train_scaled)) ** 2)\n",
    "ols_rse = np.sqrt(rss_ols / (n - k - 1))\n",
    "\n",
    "# =========================\n",
    "# 4. RIDGE (L2)\n",
    "# =========================\n",
    "\n",
    "param_grid = {'alpha': [0.01, 0.1, 1, 10, 50, 100]}\n",
    "\n",
    "ridge_grid = GridSearchCV(\n",
    "    Ridge(),\n",
    "    param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "ridge_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "ridge = ridge_grid.best_estimator_\n",
    "y_pred_ridge = ridge.predict(X_test_scaled)\n",
    "\n",
    "ridge_rmse = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
    "ridge_r2 = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "rss_ridge = np.sum((y_train - ridge.predict(X_train_scaled)) ** 2)\n",
    "ridge_rse = np.sqrt(rss_ridge / (n - k - 1))\n",
    "\n",
    "# =========================\n",
    "# 5. LASSO (L1)\n",
    "# =========================\n",
    "\n",
    "lasso_grid = GridSearchCV(\n",
    "    Lasso(max_iter=10000),\n",
    "    param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lasso_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "lasso = lasso_grid.best_estimator_\n",
    "y_pred_lasso = lasso.predict(X_test_scaled)\n",
    "\n",
    "lasso_rmse = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
    "lasso_r2 = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "rss_lasso = np.sum((y_train - lasso.predict(X_train_scaled)) ** 2)\n",
    "lasso_rse = np.sqrt(rss_lasso / (n - k - 1))\n",
    "\n",
    "# =========================\n",
    "# 6. РЕЗУЛЬТАТЫ\n",
    "# =========================\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['OLS', 'Ridge', 'Lasso'],\n",
    "    'R2_test': [ols_r2, ridge_r2, lasso_r2],\n",
    "    'RMSE_test': [ols_rmse, ridge_rmse, lasso_rmse],\n",
    "    'RSE_train': [ols_rse, ridge_rse, lasso_rse]\n",
    "})\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(\"\\nЛучшие alpha:\")\n",
    "print(f\"Ridge alpha: {ridge_grid.best_params_['alpha']}\")\n",
    "print(f\"Lasso alpha: {lasso_grid.best_params_['alpha']}\")\n",
    "\n",
    "# =========================\n",
    "# 7. КОЭФФИЦИЕНТЫ\n",
    "# =========================\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'OLS': ols.coef_,\n",
    "    'Ridge': ridge.coef_,\n",
    "    'Lasso': lasso.coef_\n",
    "})\n",
    "\n",
    "print(\"\\nКоэффициенты:\")\n",
    "print(coef_df)\n",
    "\n",
    "print(\"\\nЗанулённые коэффициенты Lasso:\")\n",
    "for feat, coef in zip(X.columns, lasso.coef_):\n",
    "    if coef == 0:\n",
    "        print(f\"- {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875216f4",
   "metadata": {},
   "source": [
    "Как видим, это нам особо тоже не помогло. Однако в методике мы разобрались. Завершая эту главу, оставим здесь несколь замечаний о полезных инструментах машинного обучения.\n",
    "\n",
    "1) Pipline. На первом этапе надо убедиться, что данные подходят для модели обучения, или улучшить их так, чтобы они подходили. Далее применяем модель обучения. Предположим, что данные требуют доработки. Тогда можно применить различные способа обработки к данным последовательно с помощью этого инструмента. Кроме того, после обработки, в том же инструменте, можно применить и разные модели обучения (или одну, если мы уже точно определился). Все это делается просто через составление словаря, который содержит набор строк, каждая из которых отражает конкретный способ обработки данных и модель обучения.\n",
    "\n",
    "2) GridSearch. Это поиск по сетке. Изначально обучаем модель на параметрах, установленных по умолчанию. Если результат неудовлетворительный, то надо отыскать такие параметры, которые устроят. Как это сделать? Желательно создать десятки или даже сотни моделей, но чтобы у каждого экземпляра модели был свой набор параметров. Каждую такую модель надо обучить и провести оценку. Найдем лучшую оценку, возьмем те параметры, с которыми модель выдала эту лучшую оценку. Именно эту задачу решает поиск по сетке. Представим таблицу. Строки - это модели. Столбцы - настраиваемые параметры. Заполняю ячейки теми значениями, которые хотим проверить. Далее берем каждую строку, обучаем, оцениваем. \n",
    "\n",
    "3) CV. Кросс-валидация. Может применяться в составе GridSearch или отдельно. Суть заключается в том, что многократно разделяю набор данных на тренировочный и тестовый. На каждом полученном наборе провожу обучение, оценку. Смотрим, какой наилучший вариант можно получить.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eb1efe",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
